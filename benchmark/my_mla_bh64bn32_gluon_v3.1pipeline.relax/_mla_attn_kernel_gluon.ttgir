#blocked = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [64, 1], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#linear = #ttg.linear<{register = [[1, 0], [2, 0], [4, 0]], lane = [[8, 0], [16, 0], [32, 0], [0, 4], [0, 8], [0, 16]], warp = [[0, 1], [0, 2]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2], [0, 4], [32, 0]], lane = [[0, 8], [0, 16], [0, 32], [4, 0], [8, 0], [16, 0]], warp = [[1, 0], [2, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 1], [0, 2], [0, 4], [16, 0], [32, 0], [64, 0], [128, 0], [256, 0]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [0, 8], [0, 16]], warp = [[0, 0], [0, 0]], block = []}>
#linear3 = #ttg.linear<{register = [[1, 0], [2, 0], [4, 0], [0, 16], [0, 32], [0, 64], [0, 128], [0, 256]], lane = [[0, 1], [0, 2], [0, 4], [0, 8], [8, 0], [16, 0]], warp = [[0, 0], [0, 0]], block = []}>
#loc = loc(unknown)
#loc1 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":228:0)
#loc115 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":449:40)
#loc125 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":453:45)
#loc177 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":501:36)
#loc185 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":505:41)
#loc208 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":534:36)
#loc216 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":538:41)
#mma = #ttg.amd_mfma<{version = 4, warpsPerCTA = [4, 1], instrShape = [16, 16, 32], isTransposed = true}>
#shared = #ttg.padded_shared<[512:+16] {order = [1, 0], shape = [64, 512]}>
#shared1 = #ttg.padded_shared<[512:+16] {offset = [[0, 1], [0, 2], [0, 4], [0, 8], [0, 16], [0, 32], [4, 0], [8, 0], [16, 0], [1, 0], [2, 0], [32, 0]], block = []}>
#shared2 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [0, 1]}>
#shared3 = #ttg.padded_shared<[512:+16] {offset = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [32, 0], [0, 4], [0, 8], [0, 16], [0, 1], [0, 2]], block = []}>
#smem = #ttg.shared_memory
#loc243 = loc("Q_nope"(#loc1))
#loc244 = loc("Q_pe"(#loc1))
#loc245 = loc("Kv_c_cache"(#loc1))
#loc246 = loc("K_pe_cache"(#loc1))
#loc247 = loc("Req_to_tokens"(#loc1))
#loc248 = loc("B_seq_len"(#loc1))
#loc249 = loc("O"(#loc1))
#loc250 = loc("sm_scale"(#loc1))
#loc251 = loc("stride_q_nope_bs"(#loc1))
#loc252 = loc("stride_q_nope_h"(#loc1))
#loc253 = loc("stride_q_pe_bs"(#loc1))
#loc254 = loc("stride_q_pe_h"(#loc1))
#loc255 = loc("stride_kv_c_bs"(#loc1))
#loc256 = loc("stride_k_pe_bs"(#loc1))
#loc257 = loc("stride_req_to_tokens_bs"(#loc1))
#loc258 = loc("stride_o_b"(#loc1))
#loc259 = loc("stride_o_h"(#loc1))
#loc260 = loc("stride_o_s"(#loc1))
#loc346 = loc("n_e_max"(#loc115))
#loc354 = loc("e_sum"(#loc125))
#loc392 = loc("n_e_max"(#loc177))
#loc400 = loc("e_sum"(#loc185))
#loc421 = loc("n_e_max"(#loc208))
#loc429 = loc("e_sum"(#loc216))
#loc458 = loc(callsite(#loc at #loc346))
#loc460 = loc(callsite(#loc at #loc354))
#loc462 = loc(callsite(#loc at #loc392))
#loc464 = loc(callsite(#loc at #loc400))
#loc466 = loc(callsite(#loc at #loc421))
#loc468 = loc(callsite(#loc at #loc429))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @_mla_attn_kernel_gluon(%Q_nope: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q_nope"(#loc1)), %Q_pe: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q_pe"(#loc1)), %Kv_c_cache: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Kv_c_cache"(#loc1)), %K_pe_cache: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("K_pe_cache"(#loc1)), %Req_to_tokens: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Req_to_tokens"(#loc1)), %B_seq_len: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("B_seq_len"(#loc1)), %O: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("O"(#loc1)), %sm_scale: f32 loc("sm_scale"(#loc1)), %stride_q_nope_bs: i32 {tt.divisibility = 16 : i32} loc("stride_q_nope_bs"(#loc1)), %stride_q_nope_h: i32 {tt.divisibility = 16 : i32} loc("stride_q_nope_h"(#loc1)), %stride_q_pe_bs: i32 {tt.divisibility = 16 : i32} loc("stride_q_pe_bs"(#loc1)), %stride_q_pe_h: i32 {tt.divisibility = 16 : i32} loc("stride_q_pe_h"(#loc1)), %stride_kv_c_bs: i32 {tt.divisibility = 16 : i32} loc("stride_kv_c_bs"(#loc1)), %stride_k_pe_bs: i32 {tt.divisibility = 16 : i32} loc("stride_k_pe_bs"(#loc1)), %stride_req_to_tokens_bs: i32 loc("stride_req_to_tokens_bs"(#loc1)), %stride_o_b: i32 {tt.divisibility = 16 : i32} loc("stride_o_b"(#loc1)), %stride_o_h: i32 {tt.divisibility = 16 : i32} loc("stride_o_h"(#loc1)), %stride_o_s: i32 {tt.divisibility = 16 : i32} loc("stride_o_s"(#loc1))) attributes {noinline = false} {
    %cst = arith.constant dense<1.000000e+00> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_0 = arith.constant dense<0xFF800000> : tensor<64x32xf32, #mma> loc(#loc)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<64x32xf32, #mma> loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %cst_2 = arith.constant dense<64> : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %cst_3 = arith.constant dense<64> : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c31_i32 = arith.constant 31 : i32 loc(#loc)
    %cst_4 = arith.constant dense<0.000000e+00> : tensor<64x512xf32, #mma> loc(#loc)
    %cst_5 = arith.constant dense<0.000000e+00> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_6 = arith.constant dense<0xFF800000> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %cur_batch = tt.get_program_id y : i32 loc(#loc261)
    %cur_head_id = tt.get_program_id x : i32 loc(#loc262)
    %split_kv_id = tt.get_program_id z : i32 loc(#loc263)
    %cur_batch_seq_len = tt.addptr %B_seq_len, %cur_batch : !tt.ptr<i32>, i32 loc(#loc264)
    %cur_batch_seq_len_7 = tt.load %cur_batch_seq_len : !tt.ptr<i32> loc(#loc265)
    %buf_q_nope = ttg.local_alloc : () -> !ttg.memdesc<64x512xbf16, #shared, #smem, mutable> loc(#loc266)
    %buf_q_pe = ttg.local_alloc : () -> !ttg.memdesc<64x64xbf16, #shared1, #smem, mutable> loc(#loc267)
    %bufs_kv = ttg.local_alloc : () -> !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> loc(#loc268)
    %bufs_kpe = ttg.local_alloc : () -> !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> loc(#loc269)
    %offs_d_ckv = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc270)
    %cur_head = arith.muli %cur_head_id, %c64_i32 : i32 loc(#loc271)
    %cur_head_8 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc272)
    %cur_head_9 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc273)
    %cur_head_10 = arith.addi %cur_head_9, %cur_head_8 : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc273)
    %offs_q_nope = arith.muli %cur_batch, %stride_q_nope_bs : i32 loc(#loc274)
    %offs_q_nope_11 = tt.expand_dims %cur_head_10 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc275)
    %offs_q_nope_12 = tt.splat %stride_q_nope_h : i32 -> tensor<64x1xi32, #blocked1> loc(#loc276)
    %offs_q_nope_13 = arith.muli %offs_q_nope_11, %offs_q_nope_12 : tensor<64x1xi32, #blocked1> loc(#loc276)
    %offs_q_nope_14 = tt.splat %offs_q_nope : i32 -> tensor<64x1xi32, #blocked1> loc(#loc277)
    %offs_q_nope_15 = arith.addi %offs_q_nope_14, %offs_q_nope_13 : tensor<64x1xi32, #blocked1> loc(#loc277)
    %offs_q_nope_16 = tt.expand_dims %offs_d_ckv {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x512xi32, #blocked1> loc(#loc278)
    %offs_q_nope_17 = tt.broadcast %offs_q_nope_15 : tensor<64x1xi32, #blocked1> -> tensor<64x512xi32, #blocked1> loc(#loc279)
    %offs_q_nope_18 = tt.broadcast %offs_q_nope_16 : tensor<1x512xi32, #blocked1> -> tensor<64x512xi32, #blocked1> loc(#loc279)
    %offs_q_nope_19 = arith.addi %offs_q_nope_17, %offs_q_nope_18 : tensor<64x512xi32, #blocked1> loc(#loc279)
    %0 = amdg.buffer_load_to_local %Q_nope[%offs_q_nope_19] into %buf_q_nope : <bf16>[tensor<64x512xi32, #blocked1>]  -> <64x512xbf16, #shared, #smem, mutable> loc(#loc21)
    %1 = ttg.async_commit_group loc(#loc22)
    %offs_d_kpe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #linear1}>> loc(#loc280)
    %cur_head_qpe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc281)
    %cur_head_qpe_20 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc282)
    %cur_head_qpe_21 = arith.addi %cur_head_qpe_20, %cur_head_qpe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc282)
    %offs_q_pe = arith.muli %cur_batch, %stride_q_pe_bs : i32 loc(#loc283)
    %offs_q_pe_22 = tt.expand_dims %cur_head_qpe_21 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<64x1xi32, #linear1> loc(#loc284)
    %offs_q_pe_23 = tt.splat %stride_q_pe_h : i32 -> tensor<64x1xi32, #linear1> loc(#loc285)
    %offs_q_pe_24 = arith.muli %offs_q_pe_22, %offs_q_pe_23 : tensor<64x1xi32, #linear1> loc(#loc285)
    %offs_q_pe_25 = tt.splat %offs_q_pe : i32 -> tensor<64x1xi32, #linear1> loc(#loc286)
    %offs_q_pe_26 = arith.addi %offs_q_pe_25, %offs_q_pe_24 : tensor<64x1xi32, #linear1> loc(#loc286)
    %offs_q_pe_27 = tt.expand_dims %offs_d_kpe {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x64xi32, #linear1> loc(#loc287)
    %offs_q_pe_28 = tt.broadcast %offs_q_pe_26 : tensor<64x1xi32, #linear1> -> tensor<64x64xi32, #linear1> loc(#loc288)
    %offs_q_pe_29 = tt.broadcast %offs_q_pe_27 : tensor<1x64xi32, #linear1> -> tensor<64x64xi32, #linear1> loc(#loc288)
    %offs_q_pe_30 = arith.addi %offs_q_pe_28, %offs_q_pe_29 : tensor<64x64xi32, #linear1> loc(#loc288)
    %2 = amdg.buffer_load_to_local %Q_pe[%offs_q_pe_30] into %buf_q_pe : <bf16>[tensor<64x64xi32, #linear1>]  -> <64x64xbf16, #shared1, #smem, mutable> loc(#loc32)
    %3 = ttg.async_commit_group loc(#loc33)
    %num_iter = arith.addi %cur_batch_seq_len_7, %c31_i32 : i32 loc(#loc454)
    %num_iter_31 = arith.divsi %num_iter, %c32_i32 : i32 loc(#loc455)
    %kv_page_number = arith.muli %stride_req_to_tokens_bs, %cur_batch : i32 loc(#loc290)
    %kv_page_number_32 = tt.addptr %Req_to_tokens, %kv_page_number : !tt.ptr<i32>, i32 loc(#loc291)
    %kv_page_number_33 = tt.load %kv_page_number_32 : !tt.ptr<i32> loc(#loc292)
    %4 = ttg.async_wait {num = 0 : i32} loc(#loc40)
    %q_nope = ttg.local_load %buf_q_nope {ttg.amdg.syncedViaAsyncWait = true} : !ttg.memdesc<64x512xbf16, #shared, #smem, mutable> -> tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc293)
    %q_pe = ttg.local_load %buf_q_pe {ttg.amdg.syncedViaAsyncWait = true} : !ttg.memdesc<64x64xbf16, #shared1, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc294)
    %offs_n = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc295)
    %kv_loc = arith.muli %kv_page_number_33, %c64_i32 : i32 loc(#loc296)
    %kv_loc_34 = arith.remsi %offs_n, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc297)
    %kv_loc_35 = tt.splat %kv_loc : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc298)
    %kv_loc_36 = arith.addi %kv_loc_35, %kv_loc_34 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc298)
    %offs_d_ckv_1 = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc299)
    %offs_k_c = tt.expand_dims %kv_loc_36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc300)
    %offs_k_c_37 = tt.splat %stride_kv_c_bs : i32 -> tensor<1x32xi32, #blocked> loc(#loc301)
    %offs_k_c_38 = arith.muli %offs_k_c, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc301)
    %offs_k_c_39 = tt.expand_dims %offs_d_ckv_1 {axis = 1 : i32} : tensor<512xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<512x1xi32, #blocked> loc(#loc302)
    %offs_k_c_40 = tt.broadcast %offs_k_c_38 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc303)
    %offs_k_c_41 = tt.broadcast %offs_k_c_39 : tensor<512x1xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc303)
    %offs_k_c_42 = arith.addi %offs_k_c_40, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc303)
    %5 = ttg.memdesc_index %bufs_kv[%c0_i32] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc52)
    %6 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_42] into %5 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc53)
    %7 = ttg.async_commit_group loc(#loc54)
    %offs_n_pe = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc304)
    %kv_loc_pe = arith.remsi %offs_n_pe, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc305)
    %kv_loc_pe_43 = tt.splat %kv_loc : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc306)
    %kv_loc_pe_44 = arith.addi %kv_loc_pe_43, %kv_loc_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc306)
    %offs_d_kpe_1 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear}>> loc(#loc307)
    %offs_k_pe = tt.expand_dims %kv_loc_pe_44 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc308)
    %offs_k_pe_45 = tt.splat %stride_k_pe_bs : i32 -> tensor<1x32xi32, #linear> loc(#loc309)
    %offs_k_pe_46 = arith.muli %offs_k_pe, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc309)
    %offs_k_pe_47 = tt.expand_dims %offs_d_kpe_1 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear}>> -> tensor<64x1xi32, #linear> loc(#loc310)
    %offs_k_pe_48 = tt.broadcast %offs_k_pe_46 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc311)
    %offs_k_pe_49 = tt.broadcast %offs_k_pe_47 : tensor<64x1xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc311)
    %offs_k_pe_50 = arith.addi %offs_k_pe_48, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc311)
    %8 = ttg.memdesc_index %bufs_kpe[%c0_i32] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc63)
    %9 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_50] into %8 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc64)
    %10 = ttg.async_commit_group loc(#loc65)
    %kv_page_number_51 = tt.load %kv_page_number_32 : !tt.ptr<i32> loc(#loc312)
    %11 = arith.cmpi sgt, %num_iter_31, %c3_i32 : i32 loc(#loc67)
    llvm.intr.assume %11 : i1 loc(#loc68)
    %12 = arith.subi %num_iter_31, %c2_i32 : i32 loc(#loc69)
    %buf_idx:6 = scf.for %buf_idx_149 = %c0_i32 to %12 step %c1_i32 iter_args(%arg19 = %cst_6, %arg20 = %cst_5, %arg21 = %cst_4, %arg22 = %c32_i32, %kv_page_number_150 = %kv_page_number_51, %arg24 = %c0_i32) -> (tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64x512xf32, #mma>, i32, i32, i32)  : i32 {
      %async_idx_151 = arith.addi %arg24, %c1_i32 : i32 loc(#loc314)
      %async_idx_152 = arith.remsi %async_idx_151, %c2_i32 : i32 loc(#loc315)
      %offs_n_153 = tt.splat %arg22 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc316)
      %offs_n_154 = arith.addi %offs_n_153, %offs_n : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc316)
      %kv_loc_155 = arith.muli %kv_page_number_150, %c64_i32 : i32 loc(#loc317)
      %kv_loc_156 = arith.remsi %offs_n_154, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc318)
      %kv_loc_157 = tt.splat %kv_loc_155 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc319)
      %kv_loc_158 = arith.addi %kv_loc_157, %kv_loc_156 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc319)
      %offs_k_c_159 = tt.expand_dims %kv_loc_158 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc320)
      %offs_k_c_160 = arith.muli %offs_k_c_159, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc321)
      %offs_k_c_161 = tt.broadcast %offs_k_c_160 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc322)
      %offs_k_c_162 = arith.addi %offs_k_c_161, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc322)
      %31 = tt.expand_dims %offs_n_154 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc80)
      %32 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #blocked> loc(#loc81)
      %33 = arith.cmpi slt, %31, %32 : tensor<1x32xi32, #blocked> loc(#loc81)
      %34 = ttg.memdesc_index %bufs_kv[%async_idx_152] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc82)
      %35 = tt.broadcast %33 : tensor<1x32xi1, #blocked> -> tensor<512x32xi1, #blocked> loc(#loc83)
      %36 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_162] mask = %35 into %34 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc83)
      %37 = ttg.async_commit_group loc(#loc84)
      %offs_n_pe_163 = tt.splat %arg22 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc323)
      %offs_n_pe_164 = arith.addi %offs_n_pe_163, %offs_n_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc323)
      %kv_loc_pe_165 = arith.remsi %offs_n_pe_164, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc324)
      %kv_loc_pe_166 = tt.splat %kv_loc_155 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc325)
      %kv_loc_pe_167 = arith.addi %kv_loc_pe_166, %kv_loc_pe_165 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc325)
      %offs_k_pe_168 = tt.expand_dims %kv_loc_pe_167 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc326)
      %offs_k_pe_169 = arith.muli %offs_k_pe_168, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc327)
      %offs_k_pe_170 = tt.broadcast %offs_k_pe_169 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc328)
      %offs_k_pe_171 = arith.addi %offs_k_pe_170, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc328)
      %38 = tt.expand_dims %offs_n_pe_164 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc91)
      %39 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #linear> loc(#loc92)
      %40 = arith.cmpi slt, %38, %39 : tensor<1x32xi32, #linear> loc(#loc92)
      %41 = ttg.memdesc_index %bufs_kpe[%async_idx_152] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc93)
      %42 = tt.broadcast %40 : tensor<1x32xi1, #linear> -> tensor<64x32xi1, #linear> loc(#loc94)
      %43 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_171] mask = %42 into %41 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc94)
      %44 = ttg.async_commit_group loc(#loc95)
      %45 = ttg.async_wait {num = 2 : i32} loc(#loc96)
      %k_c_172 = ttg.memdesc_index %bufs_kv[%arg24] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc329)
      %k_c_173 = ttg.local_load %k_c_172 {ttg.amdg.syncedViaAsyncWait = true} : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc330)
      %qk_174 = tt.dot %q_nope, %k_c_173, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc331)
      %k_pe_175 = ttg.memdesc_index %bufs_kpe[%arg24] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc332)
      %k_pe_176 = ttg.local_load %k_pe_175 {ttg.amdg.syncedViaAsyncWait = true} : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc333)
      %qk_177 = tt.dot %q_pe, %k_pe_176, %qk_174 : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc334)
      %start_n = arith.addi %arg22, %c32_i32 : i32 loc(#loc335)
      %kv_page_number_178 = arith.divsi %start_n, %c64_i32 : i32 loc(#loc336)
      %kv_page_number_179 = tt.addptr %kv_page_number_32, %kv_page_number_178 : !tt.ptr<i32>, i32 loc(#loc337)
      %kv_page_number_180 = tt.load %kv_page_number_179 : !tt.ptr<i32> loc(#loc338)
      %qk_181 = tt.splat %sm_scale : f32 -> tensor<64x32xf32, #mma> loc(#loc339)
      %qk_182 = arith.mulf %qk_177, %qk_181 : tensor<64x32xf32, #mma> loc(#loc339)
      %offs_n_qk_183 = arith.muli %buf_idx_149, %c32_i32 : i32 loc(#loc340)
      %offs_n_qk_184 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc341)
      %offs_n_qk_185 = tt.splat %offs_n_qk_183 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc342)
      %offs_n_qk_186 = arith.addi %offs_n_qk_185, %offs_n_qk_184 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc342)
      %qk_187 = tt.expand_dims %offs_n_qk_186 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc343)
      %qk_188 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #mma> loc(#loc344)
      %qk_189 = arith.cmpi slt, %qk_187, %qk_188 : tensor<1x32xi32, #mma> loc(#loc344)
      %qk_190 = tt.broadcast %qk_189 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc345)
      %qk_191 = arith.select %qk_190, %qk_182, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc345)
      %n_e_max_192 = "tt.reduce"(%qk_191) <{axis = 1 : i32}> ({
      ^bb0(%n_e_max_212: f32 loc(callsite(#loc at #loc346)), %n_e_max_213: f32 loc(callsite(#loc at #loc346))):
        %n_e_max_214 = arith.maxnumf %n_e_max_212, %n_e_max_213 : f32 loc(#loc470)
        tt.reduce.return %n_e_max_214 : f32 loc(#loc457)
      }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc457)
      %n_e_max_193 = arith.maxnumf %n_e_max_192, %arg19 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc347)
      %re_scale_194 = arith.subf %arg19, %n_e_max_193 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc348)
      %re_scale_195 = math.exp %re_scale_194 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc349)
      %p_196 = tt.expand_dims %n_e_max_193 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc350)
      %p_197 = tt.broadcast %p_196 : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc351)
      %p_198 = arith.subf %qk_191, %p_197 : tensor<64x32xf32, #mma> loc(#loc351)
      %p_199 = math.exp %p_198 : tensor<64x32xf32, #mma> loc(#loc352)
      %e_sum_200 = arith.mulf %arg20, %re_scale_195 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc353)
      %e_sum_201 = "tt.reduce"(%p_199) <{axis = 1 : i32}> ({
      ^bb0(%e_sum_212: f32 loc(callsite(#loc at #loc354)), %e_sum_213: f32 loc(callsite(#loc at #loc354))):
        %e_sum_214 = arith.addf %e_sum_212, %e_sum_213 : f32 loc(#loc471)
        tt.reduce.return %e_sum_214 : f32 loc(#loc459)
      }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc459)
      %e_sum_202 = arith.addf %e_sum_200, %e_sum_201 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc355)
      %p_203 = arith.truncf %p_199 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc356)
      %p_204 = ttg.convert_layout %p_203 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc357)
      %acc_205 = tt.expand_dims %re_scale_195 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc358)
      %acc_206 = tt.broadcast %acc_205 : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc359)
      %acc_207 = arith.mulf %arg21, %acc_206 : tensor<64x512xf32, #mma> loc(#loc359)
      %v_c_208 = ttg.local_load %k_c_172 {ttg.amdg.syncedViaAsyncWait = true} : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc360)
      %v_c_209 = tt.trans %v_c_208 {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc361)
      %v_c_210 = ttg.convert_layout %v_c_209 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc362)
      %acc_211 = tt.dot %p_204, %v_c_210, %acc_207 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc363)
      scf.yield %n_e_max_193, %e_sum_202, %acc_211, %start_n, %kv_page_number_180, %async_idx_152 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64x512xf32, #mma>, i32, i32, i32 loc(#loc136)
    } loc(#loc486)
    %async_idx = arith.addi %buf_idx#5, %c1_i32 : i32 loc(#loc364)
    %async_idx_52 = arith.remsi %async_idx, %c2_i32 : i32 loc(#loc365)
    %offs_n_53 = tt.splat %buf_idx#3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc366)
    %offs_n_54 = arith.addi %offs_n_53, %offs_n : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc366)
    %kv_loc_55 = arith.muli %buf_idx#4, %c64_i32 : i32 loc(#loc367)
    %kv_loc_56 = arith.remsi %offs_n_54, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc368)
    %kv_loc_57 = tt.splat %kv_loc_55 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc369)
    %kv_loc_58 = arith.addi %kv_loc_57, %kv_loc_56 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc369)
    %offs_k_c_59 = tt.expand_dims %kv_loc_58 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc370)
    %offs_k_c_60 = arith.muli %offs_k_c_59, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc371)
    %offs_k_c_61 = tt.broadcast %offs_k_c_60 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc372)
    %offs_k_c_62 = arith.addi %offs_k_c_61, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc372)
    %13 = tt.expand_dims %offs_n_54 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc146)
    %14 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #blocked> loc(#loc147)
    %15 = arith.cmpi slt, %13, %14 : tensor<1x32xi32, #blocked> loc(#loc147)
    %16 = ttg.memdesc_index %bufs_kv[%async_idx_52] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc148)
    %17 = tt.broadcast %15 : tensor<1x32xi1, #blocked> -> tensor<512x32xi1, #blocked> loc(#loc149)
    %18 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_62] mask = %17 into %16 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc149)
    %19 = ttg.async_commit_group loc(#loc150)
    %offs_n_pe_63 = tt.splat %buf_idx#3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc373)
    %offs_n_pe_64 = arith.addi %offs_n_pe_63, %offs_n_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc373)
    %kv_loc_pe_65 = arith.remsi %offs_n_pe_64, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc374)
    %kv_loc_pe_66 = tt.splat %kv_loc_55 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc375)
    %kv_loc_pe_67 = arith.addi %kv_loc_pe_66, %kv_loc_pe_65 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc375)
    %offs_k_pe_68 = tt.expand_dims %kv_loc_pe_67 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc376)
    %offs_k_pe_69 = arith.muli %offs_k_pe_68, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc377)
    %offs_k_pe_70 = tt.broadcast %offs_k_pe_69 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc378)
    %offs_k_pe_71 = arith.addi %offs_k_pe_70, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc378)
    %20 = tt.expand_dims %offs_n_pe_64 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc157)
    %21 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #linear> loc(#loc158)
    %22 = arith.cmpi slt, %20, %21 : tensor<1x32xi32, #linear> loc(#loc158)
    %23 = ttg.memdesc_index %bufs_kpe[%async_idx_52] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc159)
    %24 = tt.broadcast %22 : tensor<1x32xi1, #linear> -> tensor<64x32xi1, #linear> loc(#loc160)
    %25 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_71] mask = %24 into %23 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc160)
    %26 = ttg.async_commit_group loc(#loc161)
    %27 = ttg.async_wait {num = 3 : i32} loc(#loc162)
    %k_c = ttg.memdesc_index %bufs_kv[%buf_idx#5] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc379)
    %k_c_72 = ttg.local_load %k_c : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc380)
    %qk = tt.dot %q_nope, %k_c_72, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc381)
    %28 = ttg.async_wait {num = 2 : i32} loc(#loc166)
    %k_pe = ttg.memdesc_index %bufs_kpe[%buf_idx#5] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc382)
    %k_pe_73 = ttg.local_load %k_pe : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc383)
    %qk_74 = tt.dot %q_pe, %k_pe_73, %qk : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc384)
    %qk_75 = tt.splat %sm_scale : f32 -> tensor<64x32xf32, #mma> loc(#loc385)
    %qk_76 = arith.mulf %qk_74, %qk_75 : tensor<64x32xf32, #mma> loc(#loc385)
    %offs_n_qk = arith.muli %12, %c32_i32 : i32 loc(#loc386)
    %offs_n_qk_77 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc387)
    %offs_n_qk_78 = tt.splat %offs_n_qk : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc388)
    %offs_n_qk_79 = arith.addi %offs_n_qk_78, %offs_n_qk_77 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc388)
    %qk_80 = tt.expand_dims %offs_n_qk_79 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc389)
    %qk_81 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #mma> loc(#loc390)
    %qk_82 = arith.cmpi slt, %qk_80, %qk_81 : tensor<1x32xi32, #mma> loc(#loc390)
    %qk_83 = tt.broadcast %qk_82 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc391)
    %qk_84 = arith.select %qk_83, %qk_76, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc391)
    %n_e_max = "tt.reduce"(%qk_84) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_149: f32 loc(callsite(#loc at #loc392)), %n_e_max_150: f32 loc(callsite(#loc at #loc392))):
      %n_e_max_151 = arith.maxnumf %n_e_max_149, %n_e_max_150 : f32 loc(#loc472)
      tt.reduce.return %n_e_max_151 : f32 loc(#loc461)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc461)
    %n_e_max_85 = arith.maxnumf %n_e_max, %buf_idx#0 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc393)
    %re_scale = arith.subf %buf_idx#0, %n_e_max_85 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc394)
    %re_scale_86 = math.exp %re_scale : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc395)
    %p = tt.expand_dims %n_e_max_85 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc396)
    %p_87 = tt.broadcast %p : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc397)
    %p_88 = arith.subf %qk_84, %p_87 : tensor<64x32xf32, #mma> loc(#loc397)
    %p_89 = math.exp %p_88 : tensor<64x32xf32, #mma> loc(#loc398)
    %e_sum = arith.mulf %buf_idx#1, %re_scale_86 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc399)
    %e_sum_90 = "tt.reduce"(%p_89) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_149: f32 loc(callsite(#loc at #loc400)), %e_sum_150: f32 loc(callsite(#loc at #loc400))):
      %e_sum_151 = arith.addf %e_sum_149, %e_sum_150 : f32 loc(#loc473)
      tt.reduce.return %e_sum_151 : f32 loc(#loc463)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc463)
    %e_sum_91 = arith.addf %e_sum, %e_sum_90 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc401)
    %p_92 = arith.truncf %p_89 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc402)
    %p_93 = ttg.convert_layout %p_92 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc403)
    %acc = tt.expand_dims %re_scale_86 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc404)
    %acc_94 = tt.broadcast %acc : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc405)
    %acc_95 = arith.mulf %buf_idx#2, %acc_94 : tensor<64x512xf32, #mma> loc(#loc405)
    %v_c = ttg.local_load %k_c : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc406)
    %v_c_96 = tt.trans %v_c {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc407)
    %v_c_97 = ttg.convert_layout %v_c_96 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc408)
    %acc_98 = tt.dot %p_93, %v_c_97, %acc_95 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc409)
    %29 = ttg.async_wait {num = 1 : i32} loc(#loc195)
    %k_c_99 = ttg.local_load %16 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc410)
    %qk_100 = tt.dot %q_nope, %k_c_99, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc411)
    %30 = ttg.async_wait {num = 0 : i32} loc(#loc198)
    %k_pe_101 = ttg.local_load %23 : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc412)
    %qk_102 = tt.dot %q_pe, %k_pe_101, %qk_100 : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc413)
    %qk_103 = arith.mulf %qk_102, %qk_75 : tensor<64x32xf32, #mma> loc(#loc414)
    %offs_n_qk_104 = arith.subi %num_iter_31, %c1_i32 : i32 loc(#loc415)
    %offs_n_qk_105 = arith.muli %offs_n_qk_104, %c32_i32 : i32 loc(#loc416)
    %offs_n_qk_106 = tt.splat %offs_n_qk_105 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc417)
    %offs_n_qk_107 = arith.addi %offs_n_qk_106, %offs_n_qk_77 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc417)
    %qk_108 = tt.expand_dims %offs_n_qk_107 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc418)
    %qk_109 = arith.cmpi slt, %qk_108, %qk_81 : tensor<1x32xi32, #mma> loc(#loc419)
    %qk_110 = tt.broadcast %qk_109 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc420)
    %qk_111 = arith.select %qk_110, %qk_103, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc420)
    %n_e_max_112 = "tt.reduce"(%qk_111) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_149: f32 loc(callsite(#loc at #loc421)), %n_e_max_150: f32 loc(callsite(#loc at #loc421))):
      %n_e_max_151 = arith.maxnumf %n_e_max_149, %n_e_max_150 : f32 loc(#loc474)
      tt.reduce.return %n_e_max_151 : f32 loc(#loc465)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc465)
    %n_e_max_113 = arith.maxnumf %n_e_max_112, %n_e_max_85 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc422)
    %re_scale_114 = arith.subf %n_e_max_85, %n_e_max_113 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc423)
    %re_scale_115 = math.exp %re_scale_114 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc424)
    %p_116 = tt.expand_dims %n_e_max_113 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc425)
    %p_117 = tt.broadcast %p_116 : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc426)
    %p_118 = arith.subf %qk_111, %p_117 : tensor<64x32xf32, #mma> loc(#loc426)
    %p_119 = math.exp %p_118 : tensor<64x32xf32, #mma> loc(#loc427)
    %e_sum_120 = arith.mulf %e_sum_91, %re_scale_115 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc428)
    %e_sum_121 = "tt.reduce"(%p_119) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_149: f32 loc(callsite(#loc at #loc429)), %e_sum_150: f32 loc(callsite(#loc at #loc429))):
      %e_sum_151 = arith.addf %e_sum_149, %e_sum_150 : f32 loc(#loc475)
      tt.reduce.return %e_sum_151 : f32 loc(#loc467)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc467)
    %e_sum_122 = arith.addf %e_sum_120, %e_sum_121 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc430)
    %p_123 = arith.truncf %p_119 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc431)
    %p_124 = ttg.convert_layout %p_123 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc432)
    %acc_125 = tt.expand_dims %re_scale_115 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc433)
    %acc_126 = tt.broadcast %acc_125 : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc434)
    %acc_127 = arith.mulf %acc_98, %acc_126 : tensor<64x512xf32, #mma> loc(#loc434)
    %v_c_128 = ttg.local_load %16 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc435)
    %v_c_129 = tt.trans %v_c_128 {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc436)
    %v_c_130 = ttg.convert_layout %v_c_129 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc437)
    %acc_131 = tt.dot %p_124, %v_c_130, %acc_127 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc438)
    %cur_head_o = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc439)
    %cur_head_o_132 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc440)
    %cur_head_o_133 = arith.addi %cur_head_o_132, %cur_head_o : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc440)
    %offs_d_ckv_o = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc441)
    %offs_o = arith.muli %cur_batch, %stride_o_b : i32 loc(#loc442)
    %offs_o_134 = tt.expand_dims %cur_head_o_133 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xi32, #mma> loc(#loc443)
    %offs_o_135 = tt.splat %stride_o_h : i32 -> tensor<64x1xi32, #mma> loc(#loc444)
    %offs_o_136 = arith.muli %offs_o_134, %offs_o_135 : tensor<64x1xi32, #mma> loc(#loc444)
    %offs_o_137 = tt.splat %offs_o : i32 -> tensor<64x1xi32, #mma> loc(#loc445)
    %offs_o_138 = arith.addi %offs_o_137, %offs_o_136 : tensor<64x1xi32, #mma> loc(#loc445)
    %offs_o_139 = arith.muli %split_kv_id, %stride_o_s : i32 loc(#loc446)
    %offs_o_140 = tt.splat %offs_o_139 : i32 -> tensor<64x1xi32, #mma> loc(#loc447)
    %offs_o_141 = arith.addi %offs_o_138, %offs_o_140 : tensor<64x1xi32, #mma> loc(#loc447)
    %offs_o_142 = tt.expand_dims %offs_d_ckv_o {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x512xi32, #mma> loc(#loc448)
    %offs_o_143 = tt.broadcast %offs_o_141 : tensor<64x1xi32, #mma> -> tensor<64x512xi32, #mma> loc(#loc449)
    %offs_o_144 = tt.broadcast %offs_o_142 : tensor<1x512xi32, #mma> -> tensor<64x512xi32, #mma> loc(#loc449)
    %offs_o_145 = arith.addi %offs_o_143, %offs_o_144 : tensor<64x512xi32, #mma> loc(#loc449)
    %rcp = arith.divf %cst, %e_sum_122 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc450)
    %stored_value = tt.expand_dims %rcp {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc451)
    %stored_value_146 = tt.broadcast %stored_value : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc452)
    %stored_value_147 = arith.mulf %acc_131, %stored_value_146 : tensor<64x512xf32, #mma> loc(#loc452)
    %stored_value_148 = arith.truncf %stored_value_147 : tensor<64x512xf32, #mma> to tensor<64x512xbf16, #mma> loc(#loc453)
    amdg.buffer_store %stored_value_148, %O[%offs_o_145] : tensor<64x512xbf16, #mma> loc(#loc241)
    tt.return loc(#loc242)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":254:30)
#loc3 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":255:32)
#loc4 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":256:32)
#loc5 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":258:44)
#loc6 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":258:32)
#loc7 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":292:43)
#loc8 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":293:41)
#loc9 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":320:40)
#loc10 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":321:41)
#loc11 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":349:30)
#loc12 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:29)
#loc13 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:52)
#loc14 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:39)
#loc15 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:30)
#loc16 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:58)
#loc17 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:69)
#loc18 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:49)
#loc19 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:98)
#loc20 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:87)
#loc21 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":352:70)
#loc22 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":353:4)
#loc23 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":356:30)
#loc24 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":357:56)
#loc25 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":357:43)
#loc26 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:28)
#loc27 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:58)
#loc28 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:69)
#loc29 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:45)
#loc30 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:96)
#loc31 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:85)
#loc32 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":359:66)
#loc33 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":360:4)
#loc34 = loc("/home/dewwang/triton/python/triton/language/standard.py":43:17)
#loc35 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":371:37)
#loc36 = loc("/home/dewwang/triton/python/triton/language/standard.py":43:30)
#loc37 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:50)
#loc38 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:24)
#loc39 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:8)
#loc40 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":381:39)
#loc41 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":382:69)
#loc42 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":383:65)
#loc43 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":386:36)
#loc44 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":387:30)
#loc45 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":387:51)
#loc46 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":387:42)
#loc47 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":388:32)
#loc48 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":389:22)
#loc49 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":389:33)
#loc50 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":389:63)
#loc51 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":389:50)
#loc52 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:64)
#loc53 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:80)
#loc54 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":391:4)
#loc55 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":394:39)
#loc56 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":395:57)
#loc57 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":395:45)
#loc58 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":396:32)
#loc59 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":397:26)
#loc60 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":397:37)
#loc61 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":397:67)
#loc62 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":397:54)
#loc63 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:65)
#loc64 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:81)
#loc65 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":399:4)
#loc66 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":405:8)
#loc67 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":408:25)
#loc68 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":408:14)
#loc69 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":411:30)
#loc70 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":411:19)
#loc71 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":413:31)
#loc72 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":413:36)
#loc73 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":416:27)
#loc74 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":417:34)
#loc75 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":417:55)
#loc76 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":417:46)
#loc77 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":419:26)
#loc78 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":419:37)
#loc79 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":419:54)
#loc80 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:114)
#loc81 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:125)
#loc82 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:68)
#loc83 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:92)
#loc84 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":421:8)
#loc85 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":424:30)
#loc86 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":425:61)
#loc87 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":425:49)
#loc88 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":427:30)
#loc89 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":427:41)
#loc90 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":427:58)
#loc91 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:119)
#loc92 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:130)
#loc93 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:69)
#loc94 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:93)
#loc95 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":429:8)
#loc96 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":432:43)
#loc97 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":433:72)
#loc98 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":433:82)
#loc99 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":435:61)
#loc100 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":436:74)
#loc101 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":436:84)
#loc102 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":437:58)
#loc103 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":439:19)
#loc104 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":442:77)
#loc105 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":442:66)
#loc106 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":442:12)
#loc107 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":445:14)
#loc108 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":447:24)
#loc109 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":447:47)
#loc110 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":447:34)
#loc111 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":448:32)
#loc112 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":448:43)
#loc113 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":448:61)
#loc114 = loc("/home/dewwang/triton/python/triton/language/standard.py":191:40)
#loc116 = loc("/home/dewwang/triton/python/triton/language/standard.py":170:27)
#loc117 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":449:44)
#loc118 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":450:34)
#loc119 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":450:26)
#loc120 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:32)
#loc121 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:24)
#loc122 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:19)
#loc123 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":453:24)
#loc124 = loc("/home/dewwang/triton/python/triton/language/standard.py":293:36)
#loc126 = loc("/home/dewwang/triton/python/triton/language/standard.py":263:15)
#loc127 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":453:35)
#loc128 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":456:17)
#loc129 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":457:33)
#loc130 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":458:24)
#loc131 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":458:15)
#loc132 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":459:82)
#loc133 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":461:30)
#loc134 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":462:37)
#loc135 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":463:40)
#loc136 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":466:8)
#loc137 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":470:27)
#loc138 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":470:32)
#loc139 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":472:23)
#loc140 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":473:30)
#loc141 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":473:51)
#loc142 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":473:42)
#loc143 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":475:22)
#loc144 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":475:33)
#loc145 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":475:50)
#loc146 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:110)
#loc147 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:121)
#loc148 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:64)
#loc149 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:88)
#loc150 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":477:4)
#loc151 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":480:26)
#loc152 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":481:57)
#loc153 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":481:45)
#loc154 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":483:26)
#loc155 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":483:37)
#loc156 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":483:54)
#loc157 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:115)
#loc158 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:126)
#loc159 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:65)
#loc160 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:89)
#loc161 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":485:4)
#loc162 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":489:39)
#loc163 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":490:24)
#loc164 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":490:38)
#loc165 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":492:57)
#loc166 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":494:39)
#loc167 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":495:26)
#loc168 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":495:40)
#loc169 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":496:54)
#loc170 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":497:10)
#loc171 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":499:33)
#loc172 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":499:56)
#loc173 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":499:43)
#loc174 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":500:28)
#loc175 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":500:39)
#loc176 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":500:57)
#loc178 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":501:40)
#loc179 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":502:30)
#loc180 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":502:22)
#loc181 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:28)
#loc182 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:20)
#loc183 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:15)
#loc184 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":505:20)
#loc186 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":505:31)
#loc187 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":508:13)
#loc188 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":509:29)
#loc189 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":510:20)
#loc190 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":510:11)
#loc191 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":511:38)
#loc192 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":513:26)
#loc193 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":514:33)
#loc194 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":515:36)
#loc195 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":522:39)
#loc196 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":523:38)
#loc197 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":525:57)
#loc198 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":527:39)
#loc199 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":528:40)
#loc200 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":529:54)
#loc201 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":530:10)
#loc202 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":532:28)
#loc203 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":532:33)
#loc204 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":532:43)
#loc205 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":533:28)
#loc206 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":533:39)
#loc207 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":533:57)
#loc209 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":534:40)
#loc210 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":535:30)
#loc211 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":535:22)
#loc212 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:28)
#loc213 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:20)
#loc214 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:15)
#loc215 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":538:20)
#loc217 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":538:31)
#loc218 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":541:13)
#loc219 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":542:29)
#loc220 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":543:20)
#loc221 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":543:11)
#loc222 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":544:38)
#loc223 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":546:26)
#loc224 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":547:33)
#loc225 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":548:36)
#loc226 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":552:54)
#loc227 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":552:41)
#loc228 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":553:32)
#loc229 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:25)
#loc230 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:49)
#loc231 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:60)
#loc232 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:38)
#loc233 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:87)
#loc234 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:73)
#loc235 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:113)
#loc236 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":554:100)
#loc237 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:16)
#loc238 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":558:30)
#loc239 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":558:26)
#loc240 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":558:43)
#loc241 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":560:30)
#loc242 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":560:4)
#loc261 = loc("cur_batch"(#loc2))
#loc262 = loc("cur_head_id"(#loc3))
#loc263 = loc("split_kv_id"(#loc4))
#loc264 = loc("cur_batch_seq_len"(#loc5))
#loc265 = loc("cur_batch_seq_len"(#loc6))
#loc266 = loc("buf_q_nope"(#loc7))
#loc267 = loc("buf_q_pe"(#loc8))
#loc268 = loc("bufs_kv"(#loc9))
#loc269 = loc("bufs_kpe"(#loc10))
#loc270 = loc("offs_d_ckv"(#loc11))
#loc271 = loc("cur_head"(#loc12))
#loc272 = loc("cur_head"(#loc13))
#loc273 = loc("cur_head"(#loc14))
#loc274 = loc("offs_q_nope"(#loc15))
#loc275 = loc("offs_q_nope"(#loc16))
#loc276 = loc("offs_q_nope"(#loc17))
#loc277 = loc("offs_q_nope"(#loc18))
#loc278 = loc("offs_q_nope"(#loc19))
#loc279 = loc("offs_q_nope"(#loc20))
#loc280 = loc("offs_d_kpe"(#loc23))
#loc281 = loc("cur_head_qpe"(#loc24))
#loc282 = loc("cur_head_qpe"(#loc25))
#loc283 = loc("offs_q_pe"(#loc26))
#loc284 = loc("offs_q_pe"(#loc27))
#loc285 = loc("offs_q_pe"(#loc28))
#loc286 = loc("offs_q_pe"(#loc29))
#loc287 = loc("offs_q_pe"(#loc30))
#loc288 = loc("offs_q_pe"(#loc31))
#loc289 = loc("num_iter"(#loc35))
#loc290 = loc("kv_page_number"(#loc37))
#loc291 = loc("kv_page_number"(#loc38))
#loc292 = loc("kv_page_number"(#loc39))
#loc293 = loc("q_nope"(#loc41))
#loc294 = loc("q_pe"(#loc42))
#loc295 = loc("offs_n"(#loc43))
#loc296 = loc("kv_loc"(#loc44))
#loc297 = loc("kv_loc"(#loc45))
#loc298 = loc("kv_loc"(#loc46))
#loc299 = loc("offs_d_ckv_1"(#loc47))
#loc300 = loc("offs_k_c"(#loc48))
#loc301 = loc("offs_k_c"(#loc49))
#loc302 = loc("offs_k_c"(#loc50))
#loc303 = loc("offs_k_c"(#loc51))
#loc304 = loc("offs_n_pe"(#loc55))
#loc305 = loc("kv_loc_pe"(#loc56))
#loc306 = loc("kv_loc_pe"(#loc57))
#loc307 = loc("offs_d_kpe_1"(#loc58))
#loc308 = loc("offs_k_pe"(#loc59))
#loc309 = loc("offs_k_pe"(#loc60))
#loc310 = loc("offs_k_pe"(#loc61))
#loc311 = loc("offs_k_pe"(#loc62))
#loc312 = loc("kv_page_number"(#loc66))
#loc313 = loc("e_max"(#loc70))
#loc314 = loc("async_idx"(#loc71))
#loc315 = loc("async_idx"(#loc72))
#loc316 = loc("offs_n"(#loc73))
#loc317 = loc("kv_loc"(#loc74))
#loc318 = loc("kv_loc"(#loc75))
#loc319 = loc("kv_loc"(#loc76))
#loc320 = loc("offs_k_c"(#loc77))
#loc321 = loc("offs_k_c"(#loc78))
#loc322 = loc("offs_k_c"(#loc79))
#loc323 = loc("offs_n_pe"(#loc85))
#loc324 = loc("kv_loc_pe"(#loc86))
#loc325 = loc("kv_loc_pe"(#loc87))
#loc326 = loc("offs_k_pe"(#loc88))
#loc327 = loc("offs_k_pe"(#loc89))
#loc328 = loc("offs_k_pe"(#loc90))
#loc329 = loc("k_c"(#loc97))
#loc330 = loc("k_c"(#loc98))
#loc331 = loc("qk"(#loc99))
#loc332 = loc("k_pe"(#loc100))
#loc333 = loc("k_pe"(#loc101))
#loc334 = loc("qk"(#loc102))
#loc335 = loc("start_n"(#loc103))
#loc336 = loc("kv_page_number"(#loc104))
#loc337 = loc("kv_page_number"(#loc105))
#loc338 = loc("kv_page_number"(#loc106))
#loc339 = loc("qk"(#loc107))
#loc340 = loc("offs_n_qk"(#loc108))
#loc341 = loc("offs_n_qk"(#loc109))
#loc342 = loc("offs_n_qk"(#loc110))
#loc343 = loc("qk"(#loc111))
#loc344 = loc("qk"(#loc112))
#loc345 = loc("qk"(#loc113))
#loc347 = loc("n_e_max"(#loc117))
#loc348 = loc("re_scale"(#loc118))
#loc349 = loc("re_scale"(#loc119))
#loc350 = loc("p"(#loc120))
#loc351 = loc("p"(#loc121))
#loc352 = loc("p"(#loc122))
#loc353 = loc("e_sum"(#loc123))
#loc355 = loc("e_sum"(#loc127))
#loc356 = loc("p"(#loc128))
#loc357 = loc("p"(#loc129))
#loc358 = loc("acc"(#loc130))
#loc359 = loc("acc"(#loc131))
#loc360 = loc("v_c"(#loc132))
#loc361 = loc("v_c"(#loc133))
#loc362 = loc("v_c"(#loc134))
#loc363 = loc("acc"(#loc135))
#loc364 = loc("async_idx"(#loc137))
#loc365 = loc("async_idx"(#loc138))
#loc366 = loc("offs_n"(#loc139))
#loc367 = loc("kv_loc"(#loc140))
#loc368 = loc("kv_loc"(#loc141))
#loc369 = loc("kv_loc"(#loc142))
#loc370 = loc("offs_k_c"(#loc143))
#loc371 = loc("offs_k_c"(#loc144))
#loc372 = loc("offs_k_c"(#loc145))
#loc373 = loc("offs_n_pe"(#loc151))
#loc374 = loc("kv_loc_pe"(#loc152))
#loc375 = loc("kv_loc_pe"(#loc153))
#loc376 = loc("offs_k_pe"(#loc154))
#loc377 = loc("offs_k_pe"(#loc155))
#loc378 = loc("offs_k_pe"(#loc156))
#loc379 = loc("k_c"(#loc163))
#loc380 = loc("k_c"(#loc164))
#loc381 = loc("qk"(#loc165))
#loc382 = loc("k_pe"(#loc167))
#loc383 = loc("k_pe"(#loc168))
#loc384 = loc("qk"(#loc169))
#loc385 = loc("qk"(#loc170))
#loc386 = loc("offs_n_qk"(#loc171))
#loc387 = loc("offs_n_qk"(#loc172))
#loc388 = loc("offs_n_qk"(#loc173))
#loc389 = loc("qk"(#loc174))
#loc390 = loc("qk"(#loc175))
#loc391 = loc("qk"(#loc176))
#loc393 = loc("n_e_max"(#loc178))
#loc394 = loc("re_scale"(#loc179))
#loc395 = loc("re_scale"(#loc180))
#loc396 = loc("p"(#loc181))
#loc397 = loc("p"(#loc182))
#loc398 = loc("p"(#loc183))
#loc399 = loc("e_sum"(#loc184))
#loc401 = loc("e_sum"(#loc186))
#loc402 = loc("p"(#loc187))
#loc403 = loc("p"(#loc188))
#loc404 = loc("acc"(#loc189))
#loc405 = loc("acc"(#loc190))
#loc406 = loc("v_c"(#loc191))
#loc407 = loc("v_c"(#loc192))
#loc408 = loc("v_c"(#loc193))
#loc409 = loc("acc"(#loc194))
#loc410 = loc("k_c"(#loc196))
#loc411 = loc("qk"(#loc197))
#loc412 = loc("k_pe"(#loc199))
#loc413 = loc("qk"(#loc200))
#loc414 = loc("qk"(#loc201))
#loc415 = loc("offs_n_qk"(#loc202))
#loc416 = loc("offs_n_qk"(#loc203))
#loc417 = loc("offs_n_qk"(#loc204))
#loc418 = loc("qk"(#loc205))
#loc419 = loc("qk"(#loc206))
#loc420 = loc("qk"(#loc207))
#loc422 = loc("n_e_max"(#loc209))
#loc423 = loc("re_scale"(#loc210))
#loc424 = loc("re_scale"(#loc211))
#loc425 = loc("p"(#loc212))
#loc426 = loc("p"(#loc213))
#loc427 = loc("p"(#loc214))
#loc428 = loc("e_sum"(#loc215))
#loc430 = loc("e_sum"(#loc217))
#loc431 = loc("p"(#loc218))
#loc432 = loc("p"(#loc219))
#loc433 = loc("acc"(#loc220))
#loc434 = loc("acc"(#loc221))
#loc435 = loc("v_c"(#loc222))
#loc436 = loc("v_c"(#loc223))
#loc437 = loc("v_c"(#loc224))
#loc438 = loc("acc"(#loc225))
#loc439 = loc("cur_head_o"(#loc226))
#loc440 = loc("cur_head_o"(#loc227))
#loc441 = loc("offs_d_ckv_o"(#loc228))
#loc442 = loc("offs_o"(#loc229))
#loc443 = loc("offs_o"(#loc230))
#loc444 = loc("offs_o"(#loc231))
#loc445 = loc("offs_o"(#loc232))
#loc446 = loc("offs_o"(#loc233))
#loc447 = loc("offs_o"(#loc234))
#loc448 = loc("offs_o"(#loc235))
#loc449 = loc("offs_o"(#loc236))
#loc450 = loc("rcp"(#loc237))
#loc451 = loc("stored_value"(#loc238))
#loc452 = loc("stored_value"(#loc239))
#loc453 = loc("stored_value"(#loc240))
#loc454 = loc(callsite(#loc34 at #loc289))
#loc455 = loc(callsite(#loc36 at #loc289))
#loc456 = loc("e_sum"(#loc313))
#loc457 = loc(callsite(#loc114 at #loc346))
#loc459 = loc(callsite(#loc124 at #loc354))
#loc461 = loc(callsite(#loc114 at #loc392))
#loc463 = loc(callsite(#loc124 at #loc400))
#loc465 = loc(callsite(#loc114 at #loc421))
#loc467 = loc(callsite(#loc124 at #loc429))
#loc469 = loc("acc"(#loc456))
#loc470 = loc(callsite(#loc116 at #loc457))
#loc471 = loc(callsite(#loc126 at #loc459))
#loc472 = loc(callsite(#loc116 at #loc461))
#loc473 = loc(callsite(#loc126 at #loc463))
#loc474 = loc(callsite(#loc116 at #loc465))
#loc475 = loc(callsite(#loc126 at #loc467))
#loc476 = loc("start_n"(#loc469))
#loc477 = loc("kv_page_number"(#loc476))
#loc478 = loc("offs_n"(#loc477))
#loc479 = loc("kv_loc"(#loc478))
#loc480 = loc("offs_d_ckv_1"(#loc479))
#loc481 = loc("offs_k_c"(#loc480))
#loc482 = loc("offs_n_pe"(#loc481))
#loc483 = loc("kv_loc_pe"(#loc482))
#loc484 = loc("offs_d_kpe_1"(#loc483))
#loc485 = loc("offs_k_pe"(#loc484))
#loc486 = loc("buf_idx"(#loc485))
