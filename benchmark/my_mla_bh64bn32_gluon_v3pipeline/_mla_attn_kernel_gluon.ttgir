#blocked = #ttg.blocked<{sizePerThread = [8, 1], threadsPerWarp = [64, 1], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [1, 64], warpsPerCTA = [4, 1], order = [1, 0]}>
#linear = #ttg.linear<{register = [[1, 0], [2, 0], [4, 0]], lane = [[8, 0], [16, 0], [32, 0], [0, 4], [0, 8], [0, 16]], warp = [[0, 1], [0, 2]], block = []}>
#linear1 = #ttg.linear<{register = [[0, 1], [0, 2], [0, 4], [32, 0]], lane = [[0, 8], [0, 16], [0, 32], [4, 0], [8, 0], [16, 0]], warp = [[1, 0], [2, 0]], block = []}>
#linear2 = #ttg.linear<{register = [[0, 1], [0, 2], [0, 4], [16, 0], [32, 0], [64, 0], [128, 0], [256, 0]], lane = [[1, 0], [2, 0], [4, 0], [8, 0], [0, 8], [0, 16]], warp = [[0, 0], [0, 0]], block = []}>
#linear3 = #ttg.linear<{register = [[1, 0], [2, 0], [4, 0], [0, 16], [0, 32], [0, 64], [0, 128], [0, 256]], lane = [[0, 1], [0, 2], [0, 4], [0, 8], [8, 0], [16, 0]], warp = [[0, 0], [0, 0]], block = []}>
#loc = loc(unknown)
#loc1 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":228:0)
#loc117 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":452:40)
#loc127 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":456:45)
#loc179 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":504:36)
#loc187 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":508:41)
#loc210 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":537:36)
#loc218 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":541:41)
#mma = #ttg.amd_mfma<{version = 4, warpsPerCTA = [4, 1], instrShape = [16, 16, 32], isTransposed = true}>
#shared = #ttg.padded_shared<[512:+16] {order = [1, 0], shape = [64, 512]}>
#shared1 = #ttg.padded_shared<[512:+16] {offset = [[0, 1], [0, 2], [0, 4], [0, 8], [0, 16], [0, 32], [4, 0], [8, 0], [16, 0], [1, 0], [2, 0], [32, 0]], block = []}>
#shared2 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 16, order = [0, 1]}>
#shared3 = #ttg.padded_shared<[512:+16] {offset = [[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [32, 0], [0, 4], [0, 8], [0, 16], [0, 1], [0, 2]], block = []}>
#smem = #ttg.shared_memory
#loc245 = loc("Q_nope"(#loc1))
#loc246 = loc("Q_pe"(#loc1))
#loc247 = loc("Kv_c_cache"(#loc1))
#loc248 = loc("K_pe_cache"(#loc1))
#loc249 = loc("Req_to_tokens"(#loc1))
#loc250 = loc("B_seq_len"(#loc1))
#loc251 = loc("O"(#loc1))
#loc252 = loc("sm_scale"(#loc1))
#loc253 = loc("stride_q_nope_bs"(#loc1))
#loc254 = loc("stride_q_nope_h"(#loc1))
#loc255 = loc("stride_q_pe_bs"(#loc1))
#loc256 = loc("stride_q_pe_h"(#loc1))
#loc257 = loc("stride_kv_c_bs"(#loc1))
#loc258 = loc("stride_k_pe_bs"(#loc1))
#loc259 = loc("stride_req_to_tokens_bs"(#loc1))
#loc260 = loc("stride_o_b"(#loc1))
#loc261 = loc("stride_o_h"(#loc1))
#loc262 = loc("stride_o_s"(#loc1))
#loc348 = loc("n_e_max"(#loc117))
#loc356 = loc("e_sum"(#loc127))
#loc394 = loc("n_e_max"(#loc179))
#loc402 = loc("e_sum"(#loc187))
#loc423 = loc("n_e_max"(#loc210))
#loc431 = loc("e_sum"(#loc218))
#loc460 = loc(callsite(#loc at #loc348))
#loc462 = loc(callsite(#loc at #loc356))
#loc464 = loc(callsite(#loc at #loc394))
#loc466 = loc(callsite(#loc at #loc402))
#loc468 = loc(callsite(#loc at #loc423))
#loc470 = loc(callsite(#loc at #loc431))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "hip:gfx950", "ttg.threads-per-warp" = 64 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @_mla_attn_kernel_gluon(%Q_nope: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q_nope"(#loc1)), %Q_pe: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Q_pe"(#loc1)), %Kv_c_cache: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Kv_c_cache"(#loc1)), %K_pe_cache: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("K_pe_cache"(#loc1)), %Req_to_tokens: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("Req_to_tokens"(#loc1)), %B_seq_len: !tt.ptr<i32> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("B_seq_len"(#loc1)), %O: !tt.ptr<bf16> {tt.divisibility = 16 : i32, tt.pointer_range = 32 : i32} loc("O"(#loc1)), %sm_scale: f32 loc("sm_scale"(#loc1)), %stride_q_nope_bs: i32 {tt.divisibility = 16 : i32} loc("stride_q_nope_bs"(#loc1)), %stride_q_nope_h: i32 {tt.divisibility = 16 : i32} loc("stride_q_nope_h"(#loc1)), %stride_q_pe_bs: i32 {tt.divisibility = 16 : i32} loc("stride_q_pe_bs"(#loc1)), %stride_q_pe_h: i32 {tt.divisibility = 16 : i32} loc("stride_q_pe_h"(#loc1)), %stride_kv_c_bs: i32 {tt.divisibility = 16 : i32} loc("stride_kv_c_bs"(#loc1)), %stride_k_pe_bs: i32 {tt.divisibility = 16 : i32} loc("stride_k_pe_bs"(#loc1)), %stride_req_to_tokens_bs: i32 loc("stride_req_to_tokens_bs"(#loc1)), %stride_o_b: i32 {tt.divisibility = 16 : i32} loc("stride_o_b"(#loc1)), %stride_o_h: i32 {tt.divisibility = 16 : i32} loc("stride_o_h"(#loc1)), %stride_o_s: i32 {tt.divisibility = 16 : i32} loc("stride_o_s"(#loc1))) attributes {noinline = false} {
    %cst = arith.constant dense<1.000000e+00> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_0 = arith.constant dense<0xFF800000> : tensor<64x32xf32, #mma> loc(#loc)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<64x32xf32, #mma> loc(#loc)
    %c1_i32 = arith.constant 1 : i32 loc(#loc)
    %c2_i32 = arith.constant 2 : i32 loc(#loc)
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %cst_2 = arith.constant dense<64> : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %cst_3 = arith.constant dense<64> : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c31_i32 = arith.constant 31 : i32 loc(#loc)
    %cst_4 = arith.constant dense<0.000000e+00> : tensor<64x512xf32, #mma> loc(#loc)
    %cst_5 = arith.constant dense<0.000000e+00> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %cst_6 = arith.constant dense<0xFF800000> : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %cur_batch = tt.get_program_id y : i32 loc(#loc263)
    %cur_head_id = tt.get_program_id x : i32 loc(#loc264)
    %split_kv_id = tt.get_program_id z : i32 loc(#loc265)
    %cur_batch_seq_len = tt.addptr %B_seq_len, %cur_batch : !tt.ptr<i32>, i32 loc(#loc266)
    %cur_batch_seq_len_7 = tt.load %cur_batch_seq_len : !tt.ptr<i32> loc(#loc267)
    %buf_q_nope = ttg.local_alloc : () -> !ttg.memdesc<64x512xbf16, #shared, #smem, mutable> loc(#loc268)
    %buf_q_pe = ttg.local_alloc : () -> !ttg.memdesc<64x64xbf16, #shared1, #smem, mutable> loc(#loc269)
    %bufs_kv = ttg.local_alloc : () -> !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> loc(#loc270)
    %bufs_kpe = ttg.local_alloc : () -> !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> loc(#loc271)
    %offs_d_ckv = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc272)
    %cur_head = arith.muli %cur_head_id, %c64_i32 : i32 loc(#loc273)
    %cur_head_8 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc274)
    %cur_head_9 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc275)
    %cur_head_10 = arith.addi %cur_head_9, %cur_head_8 : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc275)
    %offs_q_nope = arith.muli %cur_batch, %stride_q_nope_bs : i32 loc(#loc276)
    %offs_q_nope_11 = tt.expand_dims %cur_head_10 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<64x1xi32, #blocked1> loc(#loc277)
    %offs_q_nope_12 = tt.splat %stride_q_nope_h : i32 -> tensor<64x1xi32, #blocked1> loc(#loc278)
    %offs_q_nope_13 = arith.muli %offs_q_nope_11, %offs_q_nope_12 : tensor<64x1xi32, #blocked1> loc(#loc278)
    %offs_q_nope_14 = tt.splat %offs_q_nope : i32 -> tensor<64x1xi32, #blocked1> loc(#loc279)
    %offs_q_nope_15 = arith.addi %offs_q_nope_14, %offs_q_nope_13 : tensor<64x1xi32, #blocked1> loc(#loc279)
    %offs_q_nope_16 = tt.expand_dims %offs_d_ckv {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x512xi32, #blocked1> loc(#loc280)
    %offs_q_nope_17 = tt.broadcast %offs_q_nope_15 : tensor<64x1xi32, #blocked1> -> tensor<64x512xi32, #blocked1> loc(#loc281)
    %offs_q_nope_18 = tt.broadcast %offs_q_nope_16 : tensor<1x512xi32, #blocked1> -> tensor<64x512xi32, #blocked1> loc(#loc281)
    %offs_q_nope_19 = arith.addi %offs_q_nope_17, %offs_q_nope_18 : tensor<64x512xi32, #blocked1> loc(#loc281)
    %0 = amdg.buffer_load_to_local %Q_nope[%offs_q_nope_19] into %buf_q_nope : <bf16>[tensor<64x512xi32, #blocked1>]  -> <64x512xbf16, #shared, #smem, mutable> loc(#loc21)
    %1 = ttg.async_commit_group loc(#loc22)
    %offs_d_kpe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #linear1}>> loc(#loc282)
    %cur_head_qpe = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc283)
    %cur_head_qpe_20 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc284)
    %cur_head_qpe_21 = arith.addi %cur_head_qpe_20, %cur_head_qpe : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> loc(#loc284)
    %offs_q_pe = arith.muli %cur_batch, %stride_q_pe_bs : i32 loc(#loc285)
    %offs_q_pe_22 = tt.expand_dims %cur_head_qpe_21 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear1}>> -> tensor<64x1xi32, #linear1> loc(#loc286)
    %offs_q_pe_23 = tt.splat %stride_q_pe_h : i32 -> tensor<64x1xi32, #linear1> loc(#loc287)
    %offs_q_pe_24 = arith.muli %offs_q_pe_22, %offs_q_pe_23 : tensor<64x1xi32, #linear1> loc(#loc287)
    %offs_q_pe_25 = tt.splat %offs_q_pe : i32 -> tensor<64x1xi32, #linear1> loc(#loc288)
    %offs_q_pe_26 = arith.addi %offs_q_pe_25, %offs_q_pe_24 : tensor<64x1xi32, #linear1> loc(#loc288)
    %offs_q_pe_27 = tt.expand_dims %offs_d_kpe {axis = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 0, parent = #linear1}>> -> tensor<1x64xi32, #linear1> loc(#loc289)
    %offs_q_pe_28 = tt.broadcast %offs_q_pe_26 : tensor<64x1xi32, #linear1> -> tensor<64x64xi32, #linear1> loc(#loc290)
    %offs_q_pe_29 = tt.broadcast %offs_q_pe_27 : tensor<1x64xi32, #linear1> -> tensor<64x64xi32, #linear1> loc(#loc290)
    %offs_q_pe_30 = arith.addi %offs_q_pe_28, %offs_q_pe_29 : tensor<64x64xi32, #linear1> loc(#loc290)
    %2 = amdg.buffer_load_to_local %Q_pe[%offs_q_pe_30] into %buf_q_pe : <bf16>[tensor<64x64xi32, #linear1>]  -> <64x64xbf16, #shared1, #smem, mutable> loc(#loc32)
    %3 = ttg.async_commit_group loc(#loc33)
    %num_iter = arith.addi %cur_batch_seq_len_7, %c31_i32 : i32 loc(#loc456)
    %num_iter_31 = arith.divsi %num_iter, %c32_i32 : i32 loc(#loc457)
    %kv_page_number = arith.muli %stride_req_to_tokens_bs, %cur_batch : i32 loc(#loc292)
    %kv_page_number_32 = tt.addptr %Req_to_tokens, %kv_page_number : !tt.ptr<i32>, i32 loc(#loc293)
    %kv_page_number_33 = tt.load %kv_page_number_32 : !tt.ptr<i32> loc(#loc294)
    %4 = ttg.async_wait {num = 1 : i32} loc(#loc40)
    %q_nope = ttg.local_load %buf_q_nope : !ttg.memdesc<64x512xbf16, #shared, #smem, mutable> -> tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc295)
    %5 = ttg.async_wait {num = 0 : i32} loc(#loc42)
    %q_pe = ttg.local_load %buf_q_pe : !ttg.memdesc<64x64xbf16, #shared1, #smem, mutable> -> tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc296)
    %offs_n = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc297)
    %kv_loc = arith.muli %kv_page_number_33, %c64_i32 : i32 loc(#loc298)
    %kv_loc_34 = arith.remsi %offs_n, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc299)
    %kv_loc_35 = tt.splat %kv_loc : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc300)
    %kv_loc_36 = arith.addi %kv_loc_35, %kv_loc_34 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc300)
    %offs_d_ckv_1 = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc301)
    %offs_k_c = tt.expand_dims %kv_loc_36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc302)
    %offs_k_c_37 = tt.splat %stride_kv_c_bs : i32 -> tensor<1x32xi32, #blocked> loc(#loc303)
    %offs_k_c_38 = arith.muli %offs_k_c, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc303)
    %offs_k_c_39 = tt.expand_dims %offs_d_ckv_1 {axis = 1 : i32} : tensor<512xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<512x1xi32, #blocked> loc(#loc304)
    %offs_k_c_40 = tt.broadcast %offs_k_c_38 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc305)
    %offs_k_c_41 = tt.broadcast %offs_k_c_39 : tensor<512x1xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc305)
    %offs_k_c_42 = arith.addi %offs_k_c_40, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc305)
    %6 = ttg.memdesc_index %bufs_kv[%c0_i32] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc53)
    %7 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_42] into %6 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc54)
    %8 = ttg.async_commit_group loc(#loc55)
    %offs_n_pe = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc306)
    %kv_loc_pe = arith.remsi %offs_n_pe, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc307)
    %kv_loc_pe_43 = tt.splat %kv_loc : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc308)
    %kv_loc_pe_44 = arith.addi %kv_loc_pe_43, %kv_loc_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc308)
    %offs_d_kpe_1 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear}>> loc(#loc309)
    %offs_k_pe = tt.expand_dims %kv_loc_pe_44 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc310)
    %offs_k_pe_45 = tt.splat %stride_k_pe_bs : i32 -> tensor<1x32xi32, #linear> loc(#loc311)
    %offs_k_pe_46 = arith.muli %offs_k_pe, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc311)
    %offs_k_pe_47 = tt.expand_dims %offs_d_kpe_1 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #linear}>> -> tensor<64x1xi32, #linear> loc(#loc312)
    %offs_k_pe_48 = tt.broadcast %offs_k_pe_46 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc313)
    %offs_k_pe_49 = tt.broadcast %offs_k_pe_47 : tensor<64x1xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc313)
    %offs_k_pe_50 = arith.addi %offs_k_pe_48, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc313)
    %9 = ttg.memdesc_index %bufs_kpe[%c0_i32] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc64)
    %10 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_50] into %9 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc65)
    %11 = ttg.async_commit_group loc(#loc66)
    %kv_page_number_51 = tt.load %kv_page_number_32 : !tt.ptr<i32> loc(#loc314)
    %12 = arith.cmpi sgt, %num_iter_31, %c3_i32 : i32 loc(#loc68)
    llvm.intr.assume %12 : i1 loc(#loc69)
    %13 = arith.subi %num_iter_31, %c2_i32 : i32 loc(#loc70)
    %buf_idx:6 = scf.for %buf_idx_149 = %c0_i32 to %13 step %c1_i32 iter_args(%arg19 = %cst_6, %arg20 = %cst_5, %arg21 = %cst_4, %arg22 = %c32_i32, %kv_page_number_150 = %kv_page_number_51, %arg24 = %c0_i32) -> (tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64x512xf32, #mma>, i32, i32, i32)  : i32 {
      %async_idx_151 = arith.addi %arg24, %c1_i32 : i32 loc(#loc316)
      %async_idx_152 = arith.remsi %async_idx_151, %c2_i32 : i32 loc(#loc317)
      %offs_n_153 = tt.splat %arg22 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc318)
      %offs_n_154 = arith.addi %offs_n_153, %offs_n : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc318)
      %kv_loc_155 = arith.muli %kv_page_number_150, %c64_i32 : i32 loc(#loc319)
      %kv_loc_156 = arith.remsi %offs_n_154, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc320)
      %kv_loc_157 = tt.splat %kv_loc_155 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc321)
      %kv_loc_158 = arith.addi %kv_loc_157, %kv_loc_156 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc321)
      %offs_k_c_159 = tt.expand_dims %kv_loc_158 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc322)
      %offs_k_c_160 = arith.muli %offs_k_c_159, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc323)
      %offs_k_c_161 = tt.broadcast %offs_k_c_160 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc324)
      %offs_k_c_162 = arith.addi %offs_k_c_161, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc324)
      %32 = tt.expand_dims %offs_n_154 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc81)
      %33 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #blocked> loc(#loc82)
      %34 = arith.cmpi slt, %32, %33 : tensor<1x32xi32, #blocked> loc(#loc82)
      %35 = ttg.memdesc_index %bufs_kv[%async_idx_152] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc83)
      %36 = tt.broadcast %34 : tensor<1x32xi1, #blocked> -> tensor<512x32xi1, #blocked> loc(#loc84)
      %37 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_162] mask = %36 into %35 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc84)
      %38 = ttg.async_commit_group loc(#loc85)
      %offs_n_pe_163 = tt.splat %arg22 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc325)
      %offs_n_pe_164 = arith.addi %offs_n_pe_163, %offs_n_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc325)
      %kv_loc_pe_165 = arith.remsi %offs_n_pe_164, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc326)
      %kv_loc_pe_166 = tt.splat %kv_loc_155 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc327)
      %kv_loc_pe_167 = arith.addi %kv_loc_pe_166, %kv_loc_pe_165 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc327)
      %offs_k_pe_168 = tt.expand_dims %kv_loc_pe_167 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc328)
      %offs_k_pe_169 = arith.muli %offs_k_pe_168, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc329)
      %offs_k_pe_170 = tt.broadcast %offs_k_pe_169 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc330)
      %offs_k_pe_171 = arith.addi %offs_k_pe_170, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc330)
      %39 = tt.expand_dims %offs_n_pe_164 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc92)
      %40 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #linear> loc(#loc93)
      %41 = arith.cmpi slt, %39, %40 : tensor<1x32xi32, #linear> loc(#loc93)
      %42 = ttg.memdesc_index %bufs_kpe[%async_idx_152] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc94)
      %43 = tt.broadcast %41 : tensor<1x32xi1, #linear> -> tensor<64x32xi1, #linear> loc(#loc95)
      %44 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_171] mask = %43 into %42 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc95)
      %45 = ttg.async_commit_group loc(#loc96)
      %start_n = arith.addi %arg22, %c32_i32 : i32 loc(#loc331)
      %kv_page_number_172 = arith.divsi %start_n, %c64_i32 : i32 loc(#loc332)
      %kv_page_number_173 = tt.addptr %kv_page_number_32, %kv_page_number_172 : !tt.ptr<i32>, i32 loc(#loc333)
      %kv_page_number_174 = tt.load %kv_page_number_173 : !tt.ptr<i32> loc(#loc334)
      %46 = ttg.async_wait {num = 3 : i32} loc(#loc101)
      %k_c_175 = ttg.memdesc_index %bufs_kv[%arg24] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc335)
      %k_c_176 = ttg.local_load %k_c_175 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc336)
      %qk_177 = tt.dot %q_nope, %k_c_176, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc337)
      %47 = ttg.async_wait {num = 2 : i32} loc(#loc105)
      %k_pe_178 = ttg.memdesc_index %bufs_kpe[%arg24] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc338)
      %k_pe_179 = ttg.local_load %k_pe_178 : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc339)
      %qk_180 = tt.dot %q_pe, %k_pe_179, %qk_177 : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc340)
      %qk_181 = tt.splat %sm_scale : f32 -> tensor<64x32xf32, #mma> loc(#loc341)
      %qk_182 = arith.mulf %qk_180, %qk_181 : tensor<64x32xf32, #mma> loc(#loc341)
      %offs_n_qk_183 = arith.muli %buf_idx_149, %c32_i32 : i32 loc(#loc342)
      %offs_n_qk_184 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc343)
      %offs_n_qk_185 = tt.splat %offs_n_qk_183 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc344)
      %offs_n_qk_186 = arith.addi %offs_n_qk_185, %offs_n_qk_184 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc344)
      %qk_187 = tt.expand_dims %offs_n_qk_186 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc345)
      %qk_188 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #mma> loc(#loc346)
      %qk_189 = arith.cmpi slt, %qk_187, %qk_188 : tensor<1x32xi32, #mma> loc(#loc346)
      %qk_190 = tt.broadcast %qk_189 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc347)
      %qk_191 = arith.select %qk_190, %qk_182, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc347)
      %n_e_max_192 = "tt.reduce"(%qk_191) <{axis = 1 : i32}> ({
      ^bb0(%n_e_max_212: f32 loc(callsite(#loc at #loc348)), %n_e_max_213: f32 loc(callsite(#loc at #loc348))):
        %n_e_max_214 = arith.maxnumf %n_e_max_212, %n_e_max_213 : f32 loc(#loc472)
        tt.reduce.return %n_e_max_214 : f32 loc(#loc459)
      }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc459)
      %n_e_max_193 = arith.maxnumf %n_e_max_192, %arg19 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc349)
      %re_scale_194 = arith.subf %arg19, %n_e_max_193 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc350)
      %re_scale_195 = math.exp %re_scale_194 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc351)
      %p_196 = tt.expand_dims %n_e_max_193 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc352)
      %p_197 = tt.broadcast %p_196 : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc353)
      %p_198 = arith.subf %qk_191, %p_197 : tensor<64x32xf32, #mma> loc(#loc353)
      %p_199 = math.exp %p_198 : tensor<64x32xf32, #mma> loc(#loc354)
      %e_sum_200 = arith.mulf %arg20, %re_scale_195 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc355)
      %e_sum_201 = "tt.reduce"(%p_199) <{axis = 1 : i32}> ({
      ^bb0(%e_sum_212: f32 loc(callsite(#loc at #loc356)), %e_sum_213: f32 loc(callsite(#loc at #loc356))):
        %e_sum_214 = arith.addf %e_sum_212, %e_sum_213 : f32 loc(#loc473)
        tt.reduce.return %e_sum_214 : f32 loc(#loc461)
      }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc461)
      %e_sum_202 = arith.addf %e_sum_200, %e_sum_201 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc357)
      %p_203 = arith.truncf %p_199 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc358)
      %p_204 = ttg.convert_layout %p_203 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc359)
      %acc_205 = tt.expand_dims %re_scale_195 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc360)
      %acc_206 = tt.broadcast %acc_205 : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc361)
      %acc_207 = arith.mulf %arg21, %acc_206 : tensor<64x512xf32, #mma> loc(#loc361)
      %v_c_208 = ttg.local_load %k_c_175 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc362)
      %v_c_209 = tt.trans %v_c_208 {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc363)
      %v_c_210 = ttg.convert_layout %v_c_209 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc364)
      %acc_211 = tt.dot %p_204, %v_c_210, %acc_207 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc365)
      scf.yield %n_e_max_193, %e_sum_202, %acc_211, %start_n, %kv_page_number_174, %async_idx_152 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>>, tensor<64x512xf32, #mma>, i32, i32, i32 loc(#loc138)
    } loc(#loc488)
    %async_idx = arith.addi %buf_idx#5, %c1_i32 : i32 loc(#loc366)
    %async_idx_52 = arith.remsi %async_idx, %c2_i32 : i32 loc(#loc367)
    %offs_n_53 = tt.splat %buf_idx#3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc368)
    %offs_n_54 = arith.addi %offs_n_53, %offs_n : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc368)
    %kv_loc_55 = arith.muli %buf_idx#4, %c64_i32 : i32 loc(#loc369)
    %kv_loc_56 = arith.remsi %offs_n_54, %cst_3 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc370)
    %kv_loc_57 = tt.splat %kv_loc_55 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc371)
    %kv_loc_58 = arith.addi %kv_loc_57, %kv_loc_56 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc371)
    %offs_k_c_59 = tt.expand_dims %kv_loc_58 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc372)
    %offs_k_c_60 = arith.muli %offs_k_c_59, %offs_k_c_37 : tensor<1x32xi32, #blocked> loc(#loc373)
    %offs_k_c_61 = tt.broadcast %offs_k_c_60 : tensor<1x32xi32, #blocked> -> tensor<512x32xi32, #blocked> loc(#loc374)
    %offs_k_c_62 = arith.addi %offs_k_c_61, %offs_k_c_41 : tensor<512x32xi32, #blocked> loc(#loc374)
    %14 = tt.expand_dims %offs_n_54 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc148)
    %15 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #blocked> loc(#loc149)
    %16 = arith.cmpi slt, %14, %15 : tensor<1x32xi32, #blocked> loc(#loc149)
    %17 = ttg.memdesc_index %bufs_kv[%async_idx_52] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc150)
    %18 = tt.broadcast %16 : tensor<1x32xi1, #blocked> -> tensor<512x32xi1, #blocked> loc(#loc151)
    %19 = amdg.buffer_load_to_local %Kv_c_cache[%offs_k_c_62] mask = %18 into %17 : <bf16>[tensor<512x32xi32, #blocked>]  -> <512x32xbf16, #shared2, #smem, mutable> loc(#loc151)
    %20 = ttg.async_commit_group loc(#loc152)
    %offs_n_pe_63 = tt.splat %buf_idx#3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc375)
    %offs_n_pe_64 = arith.addi %offs_n_pe_63, %offs_n_pe : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc375)
    %kv_loc_pe_65 = arith.remsi %offs_n_pe_64, %cst_2 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc376)
    %kv_loc_pe_66 = tt.splat %kv_loc_55 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc377)
    %kv_loc_pe_67 = arith.addi %kv_loc_pe_66, %kv_loc_pe_65 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> loc(#loc377)
    %offs_k_pe_68 = tt.expand_dims %kv_loc_pe_67 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc378)
    %offs_k_pe_69 = arith.muli %offs_k_pe_68, %offs_k_pe_45 : tensor<1x32xi32, #linear> loc(#loc379)
    %offs_k_pe_70 = tt.broadcast %offs_k_pe_69 : tensor<1x32xi32, #linear> -> tensor<64x32xi32, #linear> loc(#loc380)
    %offs_k_pe_71 = arith.addi %offs_k_pe_70, %offs_k_pe_49 : tensor<64x32xi32, #linear> loc(#loc380)
    %21 = tt.expand_dims %offs_n_pe_64 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #linear}>> -> tensor<1x32xi32, #linear> loc(#loc159)
    %22 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #linear> loc(#loc160)
    %23 = arith.cmpi slt, %21, %22 : tensor<1x32xi32, #linear> loc(#loc160)
    %24 = ttg.memdesc_index %bufs_kpe[%async_idx_52] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc161)
    %25 = tt.broadcast %23 : tensor<1x32xi1, #linear> -> tensor<64x32xi1, #linear> loc(#loc162)
    %26 = amdg.buffer_load_to_local %K_pe_cache[%offs_k_pe_71] mask = %25 into %24 : <bf16>[tensor<64x32xi32, #linear>]  -> <64x32xbf16, #shared3, #smem, mutable> loc(#loc162)
    %27 = ttg.async_commit_group loc(#loc163)
    %28 = ttg.async_wait {num = 3 : i32} loc(#loc164)
    %k_c = ttg.memdesc_index %bufs_kv[%buf_idx#5] : !ttg.memdesc<2x512x32xbf16, #shared2, #smem, mutable> -> !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> loc(#loc381)
    %k_c_72 = ttg.local_load %k_c : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc382)
    %qk = tt.dot %q_nope, %k_c_72, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc383)
    %29 = ttg.async_wait {num = 2 : i32} loc(#loc168)
    %k_pe = ttg.memdesc_index %bufs_kpe[%buf_idx#5] : !ttg.memdesc<2x64x32xbf16, #shared3, #smem, mutable> -> !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> loc(#loc384)
    %k_pe_73 = ttg.local_load %k_pe : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc385)
    %qk_74 = tt.dot %q_pe, %k_pe_73, %qk : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc386)
    %qk_75 = tt.splat %sm_scale : f32 -> tensor<64x32xf32, #mma> loc(#loc387)
    %qk_76 = arith.mulf %qk_74, %qk_75 : tensor<64x32xf32, #mma> loc(#loc387)
    %offs_n_qk = arith.muli %13, %c32_i32 : i32 loc(#loc388)
    %offs_n_qk_77 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc389)
    %offs_n_qk_78 = tt.splat %offs_n_qk : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc390)
    %offs_n_qk_79 = arith.addi %offs_n_qk_78, %offs_n_qk_77 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc390)
    %qk_80 = tt.expand_dims %offs_n_qk_79 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc391)
    %qk_81 = tt.splat %cur_batch_seq_len_7 : i32 -> tensor<1x32xi32, #mma> loc(#loc392)
    %qk_82 = arith.cmpi slt, %qk_80, %qk_81 : tensor<1x32xi32, #mma> loc(#loc392)
    %qk_83 = tt.broadcast %qk_82 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc393)
    %qk_84 = arith.select %qk_83, %qk_76, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc393)
    %n_e_max = "tt.reduce"(%qk_84) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_149: f32 loc(callsite(#loc at #loc394)), %n_e_max_150: f32 loc(callsite(#loc at #loc394))):
      %n_e_max_151 = arith.maxnumf %n_e_max_149, %n_e_max_150 : f32 loc(#loc474)
      tt.reduce.return %n_e_max_151 : f32 loc(#loc463)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc463)
    %n_e_max_85 = arith.maxnumf %n_e_max, %buf_idx#0 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc395)
    %re_scale = arith.subf %buf_idx#0, %n_e_max_85 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc396)
    %re_scale_86 = math.exp %re_scale : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc397)
    %p = tt.expand_dims %n_e_max_85 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc398)
    %p_87 = tt.broadcast %p : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc399)
    %p_88 = arith.subf %qk_84, %p_87 : tensor<64x32xf32, #mma> loc(#loc399)
    %p_89 = math.exp %p_88 : tensor<64x32xf32, #mma> loc(#loc400)
    %e_sum = arith.mulf %buf_idx#1, %re_scale_86 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc401)
    %e_sum_90 = "tt.reduce"(%p_89) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_149: f32 loc(callsite(#loc at #loc402)), %e_sum_150: f32 loc(callsite(#loc at #loc402))):
      %e_sum_151 = arith.addf %e_sum_149, %e_sum_150 : f32 loc(#loc475)
      tt.reduce.return %e_sum_151 : f32 loc(#loc465)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc465)
    %e_sum_91 = arith.addf %e_sum, %e_sum_90 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc403)
    %p_92 = arith.truncf %p_89 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc404)
    %p_93 = ttg.convert_layout %p_92 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc405)
    %acc = tt.expand_dims %re_scale_86 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc406)
    %acc_94 = tt.broadcast %acc : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc407)
    %acc_95 = arith.mulf %buf_idx#2, %acc_94 : tensor<64x512xf32, #mma> loc(#loc407)
    %v_c = ttg.local_load %k_c : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc408)
    %v_c_96 = tt.trans %v_c {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc409)
    %v_c_97 = ttg.convert_layout %v_c_96 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc410)
    %acc_98 = tt.dot %p_93, %v_c_97, %acc_95 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc411)
    %30 = ttg.async_wait {num = 1 : i32} loc(#loc197)
    %k_c_99 = ttg.local_load %17 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc412)
    %qk_100 = tt.dot %q_nope, %k_c_99, %cst_1 : tensor<64x512xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<512x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc413)
    %31 = ttg.async_wait {num = 0 : i32} loc(#loc200)
    %k_pe_101 = ttg.local_load %24 : !ttg.memdesc<64x32xbf16, #shared3, #smem, mutable> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc414)
    %qk_102 = tt.dot %q_pe, %k_pe_101, %qk_100 : tensor<64x64xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<64x32xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x32xf32, #mma> loc(#loc415)
    %qk_103 = arith.mulf %qk_102, %qk_75 : tensor<64x32xf32, #mma> loc(#loc416)
    %offs_n_qk_104 = arith.subi %num_iter_31, %c1_i32 : i32 loc(#loc417)
    %offs_n_qk_105 = arith.muli %offs_n_qk_104, %c32_i32 : i32 loc(#loc418)
    %offs_n_qk_106 = tt.splat %offs_n_qk_105 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc419)
    %offs_n_qk_107 = arith.addi %offs_n_qk_106, %offs_n_qk_77 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc419)
    %qk_108 = tt.expand_dims %offs_n_qk_107 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x32xi32, #mma> loc(#loc420)
    %qk_109 = arith.cmpi slt, %qk_108, %qk_81 : tensor<1x32xi32, #mma> loc(#loc421)
    %qk_110 = tt.broadcast %qk_109 : tensor<1x32xi1, #mma> -> tensor<64x32xi1, #mma> loc(#loc422)
    %qk_111 = arith.select %qk_110, %qk_103, %cst_0 : tensor<64x32xi1, #mma>, tensor<64x32xf32, #mma> loc(#loc422)
    %n_e_max_112 = "tt.reduce"(%qk_111) <{axis = 1 : i32}> ({
    ^bb0(%n_e_max_149: f32 loc(callsite(#loc at #loc423)), %n_e_max_150: f32 loc(callsite(#loc at #loc423))):
      %n_e_max_151 = arith.maxnumf %n_e_max_149, %n_e_max_150 : f32 loc(#loc476)
      tt.reduce.return %n_e_max_151 : f32 loc(#loc467)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc467)
    %n_e_max_113 = arith.maxnumf %n_e_max_112, %n_e_max_85 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc424)
    %re_scale_114 = arith.subf %n_e_max_85, %n_e_max_113 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc425)
    %re_scale_115 = math.exp %re_scale_114 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc426)
    %p_116 = tt.expand_dims %n_e_max_113 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc427)
    %p_117 = tt.broadcast %p_116 : tensor<64x1xf32, #mma> -> tensor<64x32xf32, #mma> loc(#loc428)
    %p_118 = arith.subf %qk_111, %p_117 : tensor<64x32xf32, #mma> loc(#loc428)
    %p_119 = math.exp %p_118 : tensor<64x32xf32, #mma> loc(#loc429)
    %e_sum_120 = arith.mulf %e_sum_91, %re_scale_115 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc430)
    %e_sum_121 = "tt.reduce"(%p_119) <{axis = 1 : i32}> ({
    ^bb0(%e_sum_149: f32 loc(callsite(#loc at #loc431)), %e_sum_150: f32 loc(callsite(#loc at #loc431))):
      %e_sum_151 = arith.addf %e_sum_149, %e_sum_150 : f32 loc(#loc477)
      tt.reduce.return %e_sum_151 : f32 loc(#loc469)
    }) : (tensor<64x32xf32, #mma>) -> tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc469)
    %e_sum_122 = arith.addf %e_sum_120, %e_sum_121 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc432)
    %p_123 = arith.truncf %p_119 : tensor<64x32xf32, #mma> to tensor<64x32xbf16, #mma> loc(#loc433)
    %p_124 = ttg.convert_layout %p_123 : tensor<64x32xbf16, #mma> -> tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> loc(#loc434)
    %acc_125 = tt.expand_dims %re_scale_115 {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc435)
    %acc_126 = tt.broadcast %acc_125 : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc436)
    %acc_127 = arith.mulf %acc_98, %acc_126 : tensor<64x512xf32, #mma> loc(#loc436)
    %v_c_128 = ttg.local_load %17 : !ttg.memdesc<512x32xbf16, #shared2, #smem, mutable> -> tensor<512x32xbf16, #linear2> loc(#loc437)
    %v_c_129 = tt.trans %v_c_128 {order = array<i32: 1, 0>} : tensor<512x32xbf16, #linear2> -> tensor<32x512xbf16, #linear3> loc(#loc438)
    %v_c_130 = ttg.convert_layout %v_c_129 : tensor<32x512xbf16, #linear3> -> tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> loc(#loc439)
    %acc_131 = tt.dot %p_124, %v_c_130, %acc_127 : tensor<64x32xbf16, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 8}>> * tensor<32x512xbf16, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 8}>> -> tensor<64x512xf32, #mma> loc(#loc440)
    %cur_head_o = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc441)
    %cur_head_o_132 = tt.splat %cur_head : i32 -> tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc442)
    %cur_head_o_133 = arith.addi %cur_head_o_132, %cur_head_o : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc442)
    %offs_d_ckv_o = tt.make_range {end = 512 : i32, start = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #mma}>> loc(#loc443)
    %offs_o = arith.muli %cur_batch, %stride_o_b : i32 loc(#loc444)
    %offs_o_134 = tt.expand_dims %cur_head_o_133 {axis = 1 : i32} : tensor<64xi32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xi32, #mma> loc(#loc445)
    %offs_o_135 = tt.splat %stride_o_h : i32 -> tensor<64x1xi32, #mma> loc(#loc446)
    %offs_o_136 = arith.muli %offs_o_134, %offs_o_135 : tensor<64x1xi32, #mma> loc(#loc446)
    %offs_o_137 = tt.splat %offs_o : i32 -> tensor<64x1xi32, #mma> loc(#loc447)
    %offs_o_138 = arith.addi %offs_o_137, %offs_o_136 : tensor<64x1xi32, #mma> loc(#loc447)
    %offs_o_139 = arith.muli %split_kv_id, %stride_o_s : i32 loc(#loc448)
    %offs_o_140 = tt.splat %offs_o_139 : i32 -> tensor<64x1xi32, #mma> loc(#loc449)
    %offs_o_141 = arith.addi %offs_o_138, %offs_o_140 : tensor<64x1xi32, #mma> loc(#loc449)
    %offs_o_142 = tt.expand_dims %offs_d_ckv_o {axis = 0 : i32} : tensor<512xi32, #ttg.slice<{dim = 0, parent = #mma}>> -> tensor<1x512xi32, #mma> loc(#loc450)
    %offs_o_143 = tt.broadcast %offs_o_141 : tensor<64x1xi32, #mma> -> tensor<64x512xi32, #mma> loc(#loc451)
    %offs_o_144 = tt.broadcast %offs_o_142 : tensor<1x512xi32, #mma> -> tensor<64x512xi32, #mma> loc(#loc451)
    %offs_o_145 = arith.addi %offs_o_143, %offs_o_144 : tensor<64x512xi32, #mma> loc(#loc451)
    %rcp = arith.divf %cst, %e_sum_122 : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> loc(#loc452)
    %stored_value = tt.expand_dims %rcp {axis = 1 : i32} : tensor<64xf32, #ttg.slice<{dim = 1, parent = #mma}>> -> tensor<64x1xf32, #mma> loc(#loc453)
    %stored_value_146 = tt.broadcast %stored_value : tensor<64x1xf32, #mma> -> tensor<64x512xf32, #mma> loc(#loc454)
    %stored_value_147 = arith.mulf %acc_131, %stored_value_146 : tensor<64x512xf32, #mma> loc(#loc454)
    %stored_value_148 = arith.truncf %stored_value_147 : tensor<64x512xf32, #mma> to tensor<64x512xbf16, #mma> loc(#loc455)
    amdg.buffer_store %stored_value_148, %O[%offs_o_145] : tensor<64x512xbf16, #mma> loc(#loc243)
    tt.return loc(#loc244)
  } loc(#loc1)
} loc(#loc)
#loc2 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":254:30)
#loc3 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":255:32)
#loc4 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":256:32)
#loc5 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":258:44)
#loc6 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":258:32)
#loc7 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":292:43)
#loc8 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":293:41)
#loc9 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":320:40)
#loc10 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":321:41)
#loc11 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":349:30)
#loc12 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:29)
#loc13 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:52)
#loc14 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":350:39)
#loc15 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:30)
#loc16 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:58)
#loc17 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:69)
#loc18 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:49)
#loc19 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:98)
#loc20 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":351:87)
#loc21 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":352:70)
#loc22 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":353:4)
#loc23 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":356:30)
#loc24 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":357:56)
#loc25 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":357:43)
#loc26 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:28)
#loc27 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:58)
#loc28 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:69)
#loc29 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:45)
#loc30 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:96)
#loc31 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":358:85)
#loc32 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":359:66)
#loc33 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":360:4)
#loc34 = loc("/home/dewwang/triton/python/triton/language/standard.py":43:17)
#loc35 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":371:37)
#loc36 = loc("/home/dewwang/triton/python/triton/language/standard.py":43:30)
#loc37 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:50)
#loc38 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:24)
#loc39 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":377:8)
#loc40 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":381:39)
#loc41 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":382:29)
#loc42 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":383:39)
#loc43 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":384:25)
#loc44 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":387:36)
#loc45 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":388:30)
#loc46 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":388:51)
#loc47 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":388:42)
#loc48 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":389:32)
#loc49 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:22)
#loc50 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:33)
#loc51 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:63)
#loc52 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":390:50)
#loc53 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":391:64)
#loc54 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":391:80)
#loc55 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":392:4)
#loc56 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":395:39)
#loc57 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":396:57)
#loc58 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":396:45)
#loc59 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":397:32)
#loc60 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:26)
#loc61 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:37)
#loc62 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:67)
#loc63 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":398:54)
#loc64 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":399:65)
#loc65 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":399:81)
#loc66 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":400:4)
#loc67 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":406:8)
#loc68 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":409:25)
#loc69 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":409:14)
#loc70 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":412:30)
#loc71 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":412:19)
#loc72 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":414:31)
#loc73 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":414:36)
#loc74 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":417:27)
#loc75 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":418:34)
#loc76 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":418:55)
#loc77 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":418:46)
#loc78 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:26)
#loc79 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:37)
#loc80 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":420:54)
#loc81 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":421:114)
#loc82 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":421:125)
#loc83 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":421:68)
#loc84 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":421:92)
#loc85 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":422:8)
#loc86 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":425:30)
#loc87 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":426:61)
#loc88 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":426:49)
#loc89 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:30)
#loc90 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:41)
#loc91 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":428:58)
#loc92 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":429:119)
#loc93 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":429:130)
#loc94 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":429:69)
#loc95 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":429:93)
#loc96 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":430:8)
#loc97 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":432:19)
#loc98 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":436:77)
#loc99 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":436:66)
#loc100 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":436:12)
#loc101 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":440:43)
#loc102 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":441:28)
#loc103 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":441:42)
#loc104 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":443:61)
#loc105 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":445:43)
#loc106 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":446:30)
#loc107 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":446:44)
#loc108 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":447:58)
#loc109 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":448:14)
#loc110 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":450:24)
#loc111 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":450:47)
#loc112 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":450:34)
#loc113 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:32)
#loc114 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:43)
#loc115 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":451:61)
#loc116 = loc("/home/dewwang/triton/python/triton/language/standard.py":191:40)
#loc118 = loc("/home/dewwang/triton/python/triton/language/standard.py":170:27)
#loc119 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":452:44)
#loc120 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":453:34)
#loc121 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":453:26)
#loc122 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":454:32)
#loc123 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":454:24)
#loc124 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":454:19)
#loc125 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":456:24)
#loc126 = loc("/home/dewwang/triton/python/triton/language/standard.py":293:36)
#loc128 = loc("/home/dewwang/triton/python/triton/language/standard.py":263:15)
#loc129 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":456:35)
#loc130 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":459:17)
#loc131 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":460:33)
#loc132 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":461:24)
#loc133 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":461:15)
#loc134 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":462:42)
#loc135 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":464:30)
#loc136 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":465:37)
#loc137 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":466:40)
#loc138 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":469:8)
#loc139 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":473:27)
#loc140 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":473:32)
#loc141 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":475:23)
#loc142 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:30)
#loc143 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:51)
#loc144 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":476:42)
#loc145 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":478:22)
#loc146 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":478:33)
#loc147 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":478:50)
#loc148 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":479:110)
#loc149 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":479:121)
#loc150 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":479:64)
#loc151 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":479:88)
#loc152 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":480:4)
#loc153 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":483:26)
#loc154 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:57)
#loc155 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":484:45)
#loc156 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":486:26)
#loc157 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":486:37)
#loc158 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":486:54)
#loc159 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":487:115)
#loc160 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":487:126)
#loc161 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":487:65)
#loc162 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":487:89)
#loc163 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":488:4)
#loc164 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":492:39)
#loc165 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":493:24)
#loc166 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":493:38)
#loc167 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":495:57)
#loc168 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":497:39)
#loc169 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":498:26)
#loc170 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":498:40)
#loc171 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":499:54)
#loc172 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":500:10)
#loc173 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":502:33)
#loc174 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":502:56)
#loc175 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":502:43)
#loc176 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:28)
#loc177 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:39)
#loc178 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":503:57)
#loc180 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":504:40)
#loc181 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":505:30)
#loc182 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":505:22)
#loc183 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":506:28)
#loc184 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":506:20)
#loc185 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":506:15)
#loc186 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":508:20)
#loc188 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":508:31)
#loc189 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":511:13)
#loc190 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":512:29)
#loc191 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":513:20)
#loc192 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":513:11)
#loc193 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":514:38)
#loc194 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":516:26)
#loc195 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":517:33)
#loc196 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":518:36)
#loc197 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":525:39)
#loc198 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":526:38)
#loc199 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":528:57)
#loc200 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":530:39)
#loc201 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":531:40)
#loc202 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":532:54)
#loc203 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":533:10)
#loc204 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":535:28)
#loc205 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":535:33)
#loc206 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":535:43)
#loc207 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:28)
#loc208 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:39)
#loc209 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":536:57)
#loc211 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":537:40)
#loc212 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":538:30)
#loc213 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":538:22)
#loc214 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":539:28)
#loc215 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":539:20)
#loc216 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":539:15)
#loc217 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":541:20)
#loc219 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":541:31)
#loc220 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":544:13)
#loc221 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":545:29)
#loc222 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":546:20)
#loc223 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":546:11)
#loc224 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":547:38)
#loc225 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":549:26)
#loc226 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":550:33)
#loc227 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":551:36)
#loc228 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":555:54)
#loc229 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":555:41)
#loc230 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":556:32)
#loc231 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:25)
#loc232 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:49)
#loc233 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:60)
#loc234 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:38)
#loc235 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:87)
#loc236 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:73)
#loc237 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:113)
#loc238 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":557:100)
#loc239 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":560:16)
#loc240 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":561:30)
#loc241 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":561:26)
#loc242 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":561:43)
#loc243 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":563:30)
#loc244 = loc("/home/dewwang/FlashMLA/benchmark/bench_flash_mla.v3.pipeline.py":563:4)
#loc263 = loc("cur_batch"(#loc2))
#loc264 = loc("cur_head_id"(#loc3))
#loc265 = loc("split_kv_id"(#loc4))
#loc266 = loc("cur_batch_seq_len"(#loc5))
#loc267 = loc("cur_batch_seq_len"(#loc6))
#loc268 = loc("buf_q_nope"(#loc7))
#loc269 = loc("buf_q_pe"(#loc8))
#loc270 = loc("bufs_kv"(#loc9))
#loc271 = loc("bufs_kpe"(#loc10))
#loc272 = loc("offs_d_ckv"(#loc11))
#loc273 = loc("cur_head"(#loc12))
#loc274 = loc("cur_head"(#loc13))
#loc275 = loc("cur_head"(#loc14))
#loc276 = loc("offs_q_nope"(#loc15))
#loc277 = loc("offs_q_nope"(#loc16))
#loc278 = loc("offs_q_nope"(#loc17))
#loc279 = loc("offs_q_nope"(#loc18))
#loc280 = loc("offs_q_nope"(#loc19))
#loc281 = loc("offs_q_nope"(#loc20))
#loc282 = loc("offs_d_kpe"(#loc23))
#loc283 = loc("cur_head_qpe"(#loc24))
#loc284 = loc("cur_head_qpe"(#loc25))
#loc285 = loc("offs_q_pe"(#loc26))
#loc286 = loc("offs_q_pe"(#loc27))
#loc287 = loc("offs_q_pe"(#loc28))
#loc288 = loc("offs_q_pe"(#loc29))
#loc289 = loc("offs_q_pe"(#loc30))
#loc290 = loc("offs_q_pe"(#loc31))
#loc291 = loc("num_iter"(#loc35))
#loc292 = loc("kv_page_number"(#loc37))
#loc293 = loc("kv_page_number"(#loc38))
#loc294 = loc("kv_page_number"(#loc39))
#loc295 = loc("q_nope"(#loc41))
#loc296 = loc("q_pe"(#loc43))
#loc297 = loc("offs_n"(#loc44))
#loc298 = loc("kv_loc"(#loc45))
#loc299 = loc("kv_loc"(#loc46))
#loc300 = loc("kv_loc"(#loc47))
#loc301 = loc("offs_d_ckv_1"(#loc48))
#loc302 = loc("offs_k_c"(#loc49))
#loc303 = loc("offs_k_c"(#loc50))
#loc304 = loc("offs_k_c"(#loc51))
#loc305 = loc("offs_k_c"(#loc52))
#loc306 = loc("offs_n_pe"(#loc56))
#loc307 = loc("kv_loc_pe"(#loc57))
#loc308 = loc("kv_loc_pe"(#loc58))
#loc309 = loc("offs_d_kpe_1"(#loc59))
#loc310 = loc("offs_k_pe"(#loc60))
#loc311 = loc("offs_k_pe"(#loc61))
#loc312 = loc("offs_k_pe"(#loc62))
#loc313 = loc("offs_k_pe"(#loc63))
#loc314 = loc("kv_page_number"(#loc67))
#loc315 = loc("e_max"(#loc71))
#loc316 = loc("async_idx"(#loc72))
#loc317 = loc("async_idx"(#loc73))
#loc318 = loc("offs_n"(#loc74))
#loc319 = loc("kv_loc"(#loc75))
#loc320 = loc("kv_loc"(#loc76))
#loc321 = loc("kv_loc"(#loc77))
#loc322 = loc("offs_k_c"(#loc78))
#loc323 = loc("offs_k_c"(#loc79))
#loc324 = loc("offs_k_c"(#loc80))
#loc325 = loc("offs_n_pe"(#loc86))
#loc326 = loc("kv_loc_pe"(#loc87))
#loc327 = loc("kv_loc_pe"(#loc88))
#loc328 = loc("offs_k_pe"(#loc89))
#loc329 = loc("offs_k_pe"(#loc90))
#loc330 = loc("offs_k_pe"(#loc91))
#loc331 = loc("start_n"(#loc97))
#loc332 = loc("kv_page_number"(#loc98))
#loc333 = loc("kv_page_number"(#loc99))
#loc334 = loc("kv_page_number"(#loc100))
#loc335 = loc("k_c"(#loc102))
#loc336 = loc("k_c"(#loc103))
#loc337 = loc("qk"(#loc104))
#loc338 = loc("k_pe"(#loc106))
#loc339 = loc("k_pe"(#loc107))
#loc340 = loc("qk"(#loc108))
#loc341 = loc("qk"(#loc109))
#loc342 = loc("offs_n_qk"(#loc110))
#loc343 = loc("offs_n_qk"(#loc111))
#loc344 = loc("offs_n_qk"(#loc112))
#loc345 = loc("qk"(#loc113))
#loc346 = loc("qk"(#loc114))
#loc347 = loc("qk"(#loc115))
#loc349 = loc("n_e_max"(#loc119))
#loc350 = loc("re_scale"(#loc120))
#loc351 = loc("re_scale"(#loc121))
#loc352 = loc("p"(#loc122))
#loc353 = loc("p"(#loc123))
#loc354 = loc("p"(#loc124))
#loc355 = loc("e_sum"(#loc125))
#loc357 = loc("e_sum"(#loc129))
#loc358 = loc("p"(#loc130))
#loc359 = loc("p"(#loc131))
#loc360 = loc("acc"(#loc132))
#loc361 = loc("acc"(#loc133))
#loc362 = loc("v_c"(#loc134))
#loc363 = loc("v_c"(#loc135))
#loc364 = loc("v_c"(#loc136))
#loc365 = loc("acc"(#loc137))
#loc366 = loc("async_idx"(#loc139))
#loc367 = loc("async_idx"(#loc140))
#loc368 = loc("offs_n"(#loc141))
#loc369 = loc("kv_loc"(#loc142))
#loc370 = loc("kv_loc"(#loc143))
#loc371 = loc("kv_loc"(#loc144))
#loc372 = loc("offs_k_c"(#loc145))
#loc373 = loc("offs_k_c"(#loc146))
#loc374 = loc("offs_k_c"(#loc147))
#loc375 = loc("offs_n_pe"(#loc153))
#loc376 = loc("kv_loc_pe"(#loc154))
#loc377 = loc("kv_loc_pe"(#loc155))
#loc378 = loc("offs_k_pe"(#loc156))
#loc379 = loc("offs_k_pe"(#loc157))
#loc380 = loc("offs_k_pe"(#loc158))
#loc381 = loc("k_c"(#loc165))
#loc382 = loc("k_c"(#loc166))
#loc383 = loc("qk"(#loc167))
#loc384 = loc("k_pe"(#loc169))
#loc385 = loc("k_pe"(#loc170))
#loc386 = loc("qk"(#loc171))
#loc387 = loc("qk"(#loc172))
#loc388 = loc("offs_n_qk"(#loc173))
#loc389 = loc("offs_n_qk"(#loc174))
#loc390 = loc("offs_n_qk"(#loc175))
#loc391 = loc("qk"(#loc176))
#loc392 = loc("qk"(#loc177))
#loc393 = loc("qk"(#loc178))
#loc395 = loc("n_e_max"(#loc180))
#loc396 = loc("re_scale"(#loc181))
#loc397 = loc("re_scale"(#loc182))
#loc398 = loc("p"(#loc183))
#loc399 = loc("p"(#loc184))
#loc400 = loc("p"(#loc185))
#loc401 = loc("e_sum"(#loc186))
#loc403 = loc("e_sum"(#loc188))
#loc404 = loc("p"(#loc189))
#loc405 = loc("p"(#loc190))
#loc406 = loc("acc"(#loc191))
#loc407 = loc("acc"(#loc192))
#loc408 = loc("v_c"(#loc193))
#loc409 = loc("v_c"(#loc194))
#loc410 = loc("v_c"(#loc195))
#loc411 = loc("acc"(#loc196))
#loc412 = loc("k_c"(#loc198))
#loc413 = loc("qk"(#loc199))
#loc414 = loc("k_pe"(#loc201))
#loc415 = loc("qk"(#loc202))
#loc416 = loc("qk"(#loc203))
#loc417 = loc("offs_n_qk"(#loc204))
#loc418 = loc("offs_n_qk"(#loc205))
#loc419 = loc("offs_n_qk"(#loc206))
#loc420 = loc("qk"(#loc207))
#loc421 = loc("qk"(#loc208))
#loc422 = loc("qk"(#loc209))
#loc424 = loc("n_e_max"(#loc211))
#loc425 = loc("re_scale"(#loc212))
#loc426 = loc("re_scale"(#loc213))
#loc427 = loc("p"(#loc214))
#loc428 = loc("p"(#loc215))
#loc429 = loc("p"(#loc216))
#loc430 = loc("e_sum"(#loc217))
#loc432 = loc("e_sum"(#loc219))
#loc433 = loc("p"(#loc220))
#loc434 = loc("p"(#loc221))
#loc435 = loc("acc"(#loc222))
#loc436 = loc("acc"(#loc223))
#loc437 = loc("v_c"(#loc224))
#loc438 = loc("v_c"(#loc225))
#loc439 = loc("v_c"(#loc226))
#loc440 = loc("acc"(#loc227))
#loc441 = loc("cur_head_o"(#loc228))
#loc442 = loc("cur_head_o"(#loc229))
#loc443 = loc("offs_d_ckv_o"(#loc230))
#loc444 = loc("offs_o"(#loc231))
#loc445 = loc("offs_o"(#loc232))
#loc446 = loc("offs_o"(#loc233))
#loc447 = loc("offs_o"(#loc234))
#loc448 = loc("offs_o"(#loc235))
#loc449 = loc("offs_o"(#loc236))
#loc450 = loc("offs_o"(#loc237))
#loc451 = loc("offs_o"(#loc238))
#loc452 = loc("rcp"(#loc239))
#loc453 = loc("stored_value"(#loc240))
#loc454 = loc("stored_value"(#loc241))
#loc455 = loc("stored_value"(#loc242))
#loc456 = loc(callsite(#loc34 at #loc291))
#loc457 = loc(callsite(#loc36 at #loc291))
#loc458 = loc("e_sum"(#loc315))
#loc459 = loc(callsite(#loc116 at #loc348))
#loc461 = loc(callsite(#loc126 at #loc356))
#loc463 = loc(callsite(#loc116 at #loc394))
#loc465 = loc(callsite(#loc126 at #loc402))
#loc467 = loc(callsite(#loc116 at #loc423))
#loc469 = loc(callsite(#loc126 at #loc431))
#loc471 = loc("acc"(#loc458))
#loc472 = loc(callsite(#loc118 at #loc459))
#loc473 = loc(callsite(#loc128 at #loc461))
#loc474 = loc(callsite(#loc118 at #loc463))
#loc475 = loc(callsite(#loc128 at #loc465))
#loc476 = loc(callsite(#loc118 at #loc467))
#loc477 = loc(callsite(#loc128 at #loc469))
#loc478 = loc("start_n"(#loc471))
#loc479 = loc("kv_page_number"(#loc478))
#loc480 = loc("offs_n"(#loc479))
#loc481 = loc("kv_loc"(#loc480))
#loc482 = loc("offs_d_ckv_1"(#loc481))
#loc483 = loc("offs_k_c"(#loc482))
#loc484 = loc("offs_n_pe"(#loc483))
#loc485 = loc("kv_loc_pe"(#loc484))
#loc486 = loc("offs_d_kpe_1"(#loc485))
#loc487 = loc("offs_k_pe"(#loc486))
#loc488 = loc("buf_idx"(#loc487))
